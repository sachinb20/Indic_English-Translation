{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5-CIb-pub_0F"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from typing import Iterable, List\n",
        "import math\n",
        "from tempfile import TemporaryDirectory\n",
        "from typing import Tuple\n",
        "from torch import nn, Tensor\n",
        "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
        "from torch.utils.data import Dataset, IterableDataset, DataLoader, TensorDataset\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch import Tensor\n",
        "from torch.nn import Transformer\n",
        "import math\n",
        "from timeit import default_timer as timer\n",
        "\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu') #set the device as GPU if available"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jok77llycOGB"
      },
      "outputs": [],
      "source": [
        "EMB_SIZE = 400\n",
        "NHEAD = 2\n",
        "FFN_HID_DIM = 128\n",
        "BATCH_SIZE = 16\n",
        "NUM_ENCODER_LAYERS = 4\n",
        "NUM_DECODER_LAYERS = 4\n",
        "lr = 0.0001\n",
        "betas = (0.9, 0.98)\n",
        "eps = 1e-9\n",
        "NUM_EPOCHS = 36 #the result given will come if NUM_EPOCHS is set to 36.\n",
        "split_size = 0.1\n",
        "\n",
        "SRC_LANGUAGE = 'hi'\n",
        "TGT_LANGUAGE = 'en'\n",
        "\n",
        "# vocab_size = {}\n",
        "# vocab_size[SRC_LANGUAGE] = 7000\n",
        "# vocab_size[TGT_LANGUAGE] = 7000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tM_1MYZAaEHF",
        "outputId": "c210158b-da58-4e11-b514-5f807a999f40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#uncomment the following to mount while using colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BxlDP07BVfgZ"
      },
      "outputs": [],
      "source": [
        "!mkdir -p \"/content/drive/My Drive/My Folder1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h_wJIlrqcQgO"
      },
      "outputs": [],
      "source": [
        "Lang = 'HG'\n",
        "answer_filename = '/content/drive/My Drive/My Folder1/answer_'+Lang +'.txt'\n",
        "model_filename = '/content/drive/My Drive/My Folder1/model_'+Lang +'.pt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "LHFZbqbwc-hf",
        "outputId": "b5f87761-9c61-4e83-8d35-48e0673898b1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               hindi  \\\n",
              "0  મરી, આદુ, એલચી અને હળદર જેવા સુગંધિત છોડ અને મ...   \n",
              "1  ઇન્દોર જિલ્લાની તમામ બ્લડ બેંકમાંથી ઓછામાં ઓછા...   \n",
              "2  મેલબોર્નમાં તેના ગુમ થયા પછીના દિવસોમાં તેની ફ...   \n",
              "3  જો ચંદ્રગુપ્તએ કર્ણાટકમાં ત્યાગ તરીકે પોતાનું ...   \n",
              "4  જમીન પર નિશાન કરવા અને બીજને યોગ્ય ભાર કે વજન ...   \n",
              "\n",
              "                                             english  \n",
              "0  Aromatic plants and spices such as pepper, gin...  \n",
              "1  Find all blood banks having atleast 1 units of...  \n",
              "2  His Ford sedan was sighted via CCTV footage in...  \n",
              "3  If the Jain tradition about Chandragupta endin...  \n",
              "4  Marking out the land and weighing the seed int...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3a254096-2e6a-4e6a-80e9-cce72bdd367a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>hindi</th>\n",
              "      <th>english</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>મરી, આદુ, એલચી અને હળદર જેવા સુગંધિત છોડ અને મ...</td>\n",
              "      <td>Aromatic plants and spices such as pepper, gin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ઇન્દોર જિલ્લાની તમામ બ્લડ બેંકમાંથી ઓછામાં ઓછા...</td>\n",
              "      <td>Find all blood banks having atleast 1 units of...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>મેલબોર્નમાં તેના ગુમ થયા પછીના દિવસોમાં તેની ફ...</td>\n",
              "      <td>His Ford sedan was sighted via CCTV footage in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>જો ચંદ્રગુપ્તએ કર્ણાટકમાં ત્યાગ તરીકે પોતાનું ...</td>\n",
              "      <td>If the Jain tradition about Chandragupta endin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>જમીન પર નિશાન કરવા અને બીજને યોગ્ય ભાર કે વજન ...</td>\n",
              "      <td>Marking out the land and weighing the seed int...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3a254096-2e6a-4e6a-80e9-cce72bdd367a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3a254096-2e6a-4e6a-80e9-cce72bdd367a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3a254096-2e6a-4e6a-80e9-cce72bdd367a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9a3adb82-43af-4319-9798-27a31ffdad42\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9a3adb82-43af-4319-9798-27a31ffdad42')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9a3adb82-43af-4319-9798-27a31ffdad42 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "#loading data from the desired directory\n",
        "DATA_PATH = '/content/drive/MyDrive/Machine_Translation_Data/English_'+Lang+'.csv'\n",
        "# TEST_PATH = '/kaggle/input/cs779-mt/eng_Hindi_data_dev_X.csv'\n",
        "FINAL_TEST_DATA = '/content/drive/MyDrive/Machine_Translation_Data/English_'+Lang+'_val.csv'\n",
        "data = pd.read_csv(DATA_PATH, header = None)\n",
        "data.columns = ['hindi', 'english']\n",
        "\n",
        "# test = pd.read_csv(TEST_PATH, header = None)\n",
        "# test.columns = ['sentence']\n",
        "final_test_data = pd.read_csv(FINAL_TEST_DATA, header = None)\n",
        "final_test_data.columns = ['sentence']\n",
        "data.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "rQu11ChUr28V",
        "outputId": "5fadeb5d-820b-4f10-fffb-2df916f40127"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             english  \\\n",
              "0  Aromatic plants and spices such as pepper, gin...   \n",
              "1  Find all blood banks having atleast 1 units of...   \n",
              "2  His Ford sedan was sighted via CCTV footage in...   \n",
              "3  If the Jain tradition about Chandragupta endin...   \n",
              "4  Marking out the land and weighing the seed int...   \n",
              "\n",
              "                                               hindi  \n",
              "0  મરી, આદુ, એલચી અને હળદર જેવા સુગંધિત છોડ અને મ...  \n",
              "1  ઇન્દોર જિલ્લાની તમામ બ્લડ બેંકમાંથી ઓછામાં ઓછા...  \n",
              "2  મેલબોર્નમાં તેના ગુમ થયા પછીના દિવસોમાં તેની ફ...  \n",
              "3  જો ચંદ્રગુપ્તએ કર્ણાટકમાં ત્યાગ તરીકે પોતાનું ...  \n",
              "4  જમીન પર નિશાન કરવા અને બીજને યોગ્ય ભાર કે વજન ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d4ae6b8c-456f-4609-9240-c82509d03864\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>english</th>\n",
              "      <th>hindi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Aromatic plants and spices such as pepper, gin...</td>\n",
              "      <td>મરી, આદુ, એલચી અને હળદર જેવા સુગંધિત છોડ અને મ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Find all blood banks having atleast 1 units of...</td>\n",
              "      <td>ઇન્દોર જિલ્લાની તમામ બ્લડ બેંકમાંથી ઓછામાં ઓછા...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>His Ford sedan was sighted via CCTV footage in...</td>\n",
              "      <td>મેલબોર્નમાં તેના ગુમ થયા પછીના દિવસોમાં તેની ફ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>If the Jain tradition about Chandragupta endin...</td>\n",
              "      <td>જો ચંદ્રગુપ્તએ કર્ણાટકમાં ત્યાગ તરીકે પોતાનું ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Marking out the land and weighing the seed int...</td>\n",
              "      <td>જમીન પર નિશાન કરવા અને બીજને યોગ્ય ભાર કે વજન ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d4ae6b8c-456f-4609-9240-c82509d03864')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d4ae6b8c-456f-4609-9240-c82509d03864 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d4ae6b8c-456f-4609-9240-c82509d03864');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-87d1a78a-f540-42ab-b86d-be223beba5f5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-87d1a78a-f540-42ab-b86d-be223beba5f5')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-87d1a78a-f540-42ab-b86d-be223beba5f5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "def swap_columns(df, col1, col2):\n",
        "    col_list = list(df.columns)\n",
        "    x, y = col_list.index(col1), col_list.index(col2)\n",
        "    col_list[y], col_list[x] = col_list[x], col_list[y]\n",
        "    df = df[col_list]\n",
        "    return df\n",
        "\n",
        "data = swap_columns(data, 'hindi', 'english')\n",
        "data.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4IAvDq2JBVpH",
        "outputId": "04b0b082-a55e-44c9-bd75-def90276f303"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         મરી, આદુ, એલચી અને હળદર જેવા સુગંધિત છોડ અને મ...\n",
              "1         ઇન્દોર જિલ્લાની તમામ બ્લડ બેંકમાંથી ઓછામાં ઓછા...\n",
              "2         મેલબોર્નમાં તેના ગુમ થયા પછીના દિવસોમાં તેની ફ...\n",
              "3         જો ચંદ્રગુપ્તએ કર્ણાટકમાં ત્યાગ તરીકે પોતાનું ...\n",
              "4         જમીન પર નિશાન કરવા અને બીજને યોગ્ય ભાર કે વજન ...\n",
              "                                ...                        \n",
              "128274            2021-22 प्रो कबड्डी लीग का आठवां सत्र है।\n",
              "128275    कभी-कभी प्रयोगशाला में बाहर के कर्मचारी जांच क...\n",
              "128276                                       3. आम रोगजनकों\n",
              "128277    दिन 2 हरिद्वार बारकोट 220kilomItara 7 घंटे देह...\n",
              "128278    खेत में नमी की कमी होने पर सिंचाई नितान्त आवश्...\n",
              "Name: hindi, Length: 128279, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "data['hindi']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BopFDyDR_ygL"
      },
      "outputs": [],
      "source": [
        "data['english'] = data['english'].apply(str)\n",
        "data['hindi'] = data['hindi'].apply(str)\n",
        "final_test_data['sentence'] = final_test_data['sentence'].apply(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yF7E3Wan9TJg",
        "outputId": "8b5f9821-8b38-4daa-dbb5-952ca4bb2bae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'indic_nlp_library' already exists and is not an empty directory.\n",
            "fatal: destination path 'indic_nlp_resources' already exists and is not an empty directory.\n",
            "Requirement already satisfied: Morfessor in /usr/local/lib/python3.10/dist-packages (2.0.6)\n"
          ]
        }
      ],
      "source": [
        "!git clone \"https://github.com/anoopkunchukuttan/indic_nlp_library\"\n",
        "!git clone https://github.com/anoopkunchukuttan/indic_nlp_resources.git\n",
        "!pip install Morfessor\n",
        "# The path to the local git repo for Indic NLP library\n",
        "INDIC_NLP_LIB_HOME=r\"/content/indic_nlp_library\"\n",
        "\n",
        "# The path to the local git repo for Indic NLP Resources\n",
        "INDIC_NLP_RESOURCES=\"/content/indic_nlp_resources\"\n",
        "\n",
        "import sys\n",
        "sys.path.append(r'{}'.format(INDIC_NLP_LIB_HOME))\n",
        "from indicnlp import common\n",
        "common.set_resources_path(INDIC_NLP_RESOURCES)\n",
        "from indicnlp import loader\n",
        "loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "ue7w-tQ63p9y",
        "outputId": "dd46922b-2606-498f-e1ea-31d4ff967595"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(115451, 2)\n",
            "(12828, 2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             english  \\\n",
              "0  Winter rice crop is raised preferably in low l...   \n",
              "1  With so much going on, Humayun did not even me...   \n",
              "2  When the need of rest to be given to the tired...   \n",
              "3  The use of \"Mughal\" and \"Moghul\" derived from ...   \n",
              "4  Therefore , every person should stay beware of...   \n",
              "\n",
              "                                               hindi  \n",
              "0  શિયાળુ ચોખાનો પાક નીચા સ્તરવાળા વિસ્તારમાં ઉગા...  \n",
              "1  આટલું બધું ચાલતું હોવાથી, હુમાયુ પર્શિયામાં તે...  \n",
              "2  દિવસમાં ત્રણ પ્યાલા ચા પીવાથી માસપેશિયોમાં ખેં...  \n",
              "3  \"मुगल\" और \"मोगल\" का उपयोग \"मंगोल\" के अरबी और फ...  \n",
              "4        अतः हर व्यक्ति को इस से सावधान रहना चाहिए ।  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-12e87bef-7f93-496e-b257-4fc093ffb42b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>english</th>\n",
              "      <th>hindi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Winter rice crop is raised preferably in low l...</td>\n",
              "      <td>શિયાળુ ચોખાનો પાક નીચા સ્તરવાળા વિસ્તારમાં ઉગા...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>With so much going on, Humayun did not even me...</td>\n",
              "      <td>આટલું બધું ચાલતું હોવાથી, હુમાયુ પર્શિયામાં તે...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>When the need of rest to be given to the tired...</td>\n",
              "      <td>દિવસમાં ત્રણ પ્યાલા ચા પીવાથી માસપેશિયોમાં ખેં...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The use of \"Mughal\" and \"Moghul\" derived from ...</td>\n",
              "      <td>\"मुगल\" और \"मोगल\" का उपयोग \"मंगोल\" के अरबी और फ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Therefore , every person should stay beware of...</td>\n",
              "      <td>अतः हर व्यक्ति को इस से सावधान रहना चाहिए ।</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-12e87bef-7f93-496e-b257-4fc093ffb42b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-12e87bef-7f93-496e-b257-4fc093ffb42b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-12e87bef-7f93-496e-b257-4fc093ffb42b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0002e268-5713-4435-ab83-fab102c8bbb9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0002e268-5713-4435-ab83-fab102c8bbb9')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0002e268-5713-4435-ab83-fab102c8bbb9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "#train test split using sklearn\n",
        "train, eval = train_test_split(data, test_size = split_size, random_state = 42)\n",
        "train = train.reset_index(drop = True)\n",
        "eval = eval.reset_index(drop = True)\n",
        "print(train.shape)\n",
        "print(eval.shape)\n",
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UcUSb4mI3TRV"
      },
      "outputs": [],
      "source": [
        "#defining the iterable class for creating the iterable dataset\n",
        "#it takes two series as input namely hindi and english sentence series and\n",
        "#generates a tuple of source and target sentence as follows\n",
        "class MyIterableDataset(IterableDataset):\n",
        "    def __init__(self, english_sentences, hindi_sentences):\n",
        "        self.english_sentences = english_sentences\n",
        "        self.hindi_sentences = hindi_sentences\n",
        "        self.index = 0\n",
        "\n",
        "    def __iter__(self):\n",
        "        return self\n",
        "\n",
        "    def __next__(self):\n",
        "        if self.index >= len(self.english_sentences):\n",
        "            raise StopIteration\n",
        "        else:\n",
        "            english_sentence = self.english_sentences[self.index]\n",
        "            hindi_sentence = self.hindi_sentences[self.index]\n",
        "            self.index += 1\n",
        "            return hindi_sentence, english_sentence\n",
        "\n",
        "# Example usage\n",
        "train_iter = MyIterableDataset(train['english'], train['hindi'])\n",
        "eval_iter = MyIterableDataset(eval['english'], eval['hindi'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ciihdBj98qQ"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "# !python -m spacy download en_core_web_sm\n",
        "eng = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "from indicnlp.tokenize import indic_tokenize\n",
        "\n",
        "def engTokenize(text):\n",
        "    \"\"\"\n",
        "    Tokenize an English text and return a list of tokens\n",
        "    \"\"\"\n",
        "    return [str(token.text) for token in eng.tokenizer(str(text))]\n",
        "\n",
        "def hiTokenize(text):\n",
        "    \"\"\"\n",
        "    Tokenize a German text and return a list of tokens\n",
        "    \"\"\"\n",
        "    return [str(t) for t in indic_tokenize.trivial_tokenize(str(text))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cJ0QbyUg_Mfm"
      },
      "outputs": [],
      "source": [
        "# def getTokens(data_iter, place):\n",
        "#     \"\"\"\n",
        "#     Function to yield tokens from an iterator. Since, our iterator contains\n",
        "#     tuple of sentences (source and target), `place` parameters defines for which\n",
        "#     index to return the tokens for. `place=0` for source and `place=1` for target\n",
        "#     \"\"\"\n",
        "#     for english, german in data_iter:\n",
        "#         if place == 0:\n",
        "#             yield engTokenize(english)\n",
        "#         else:\n",
        "#             yield hiTokenize(german)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = {}\n",
        "vocab_size[SRC_LANGUAGE] = 60000\n",
        "vocab_size[TGT_LANGUAGE] = 40000"
      ],
      "metadata": {
        "id": "tkTPmSTKHXSB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WFJQouRvEwmb"
      },
      "outputs": [],
      "source": [
        "# Place-holders\n",
        "token_transform = {}\n",
        "vocab_transform = {}\n",
        "\n",
        "token_transform[SRC_LANGUAGE] = hiTokenize\n",
        "token_transform[TGT_LANGUAGE] = engTokenize\n",
        "\n",
        "# function to generate the tokens for each language\n",
        "def yield_tokens(data_iter: Iterable, language: str) -> List[str]:\n",
        "    language_index = {SRC_LANGUAGE: 0, TGT_LANGUAGE: 1}\n",
        "\n",
        "    for data_sample in data_iter:\n",
        "        yield token_transform[language](data_sample[language_index[language]])\n",
        "\n",
        "# Define special symbols and indices\n",
        "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
        "special_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']\n",
        "\n",
        "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
        "    #create the iterator object of the dataset given\n",
        "    train_iter = MyIterableDataset(train['english'], train['hindi'])\n",
        "    vocab_transform[ln] = build_vocab_from_iterator(yield_tokens(train_iter, ln),\n",
        "                                                    min_freq=2,\n",
        "                                                    specials=special_symbols,\n",
        "                                                    special_first=True,\n",
        "                                                    max_tokens = vocab_size[ln]\n",
        "                                                    )\n",
        "\n",
        "#setting the default index to unknown index which means that it will assume the token to be unknown if\n",
        "#it sees a word not in the dictionary.\n",
        "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
        "  vocab_transform[ln].set_default_index(UNK_IDX)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(vocab_transform['en'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "inhEqCIJ1W3U",
        "outputId": "382ed013-0494-473a-9949-d104a017b63c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "40000"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(vocab_transform['hi'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDu-RUaU1XWe",
        "outputId": "d0299d75-e5cd-470c-a658-3e9a0a4567b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60000"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJ4vOSVZO-W0",
        "outputId": "525b6572-7218-424f-f62c-580f2a869484"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tokenized hindi sentence  ['Winter', 'rice', 'crop', 'is', 'raised', 'preferably', 'in', 'low', 'lying', 'areas', 'that', 'remain', 'flooded', 'mainly', 'during', 'the', 'rainy', 'season', '.']\n",
            "numericalized hindi sentence  [5489, 638, 250, 10, 1972, 4624, 9, 500, 2506, 255, 17, 776, 12849, 933, 114, 4, 3177, 465, 5]\n"
          ]
        }
      ],
      "source": [
        "print(\"tokenized hindi sentence \", token_transform['en'](train['english'][0]))\n",
        "print(\"numericalized hindi sentence \", vocab_transform['en'](token_transform['hi'](train['english'][0])))\n",
        "#check for the correct tokenization and numericalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "taLWE2OLaCJJ"
      },
      "outputs": [],
      "source": [
        "# helper Module that adds positional encoding to the token embedding to introduce a notion of word order.\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self,\n",
        "                 emb_size: int,\n",
        "                 dropout: float,\n",
        "                 maxlen: int = 7000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        den = torch.exp(- torch.arange(0, emb_size, 2)* math.log(10000) / emb_size)\n",
        "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
        "        pos_embedding = torch.zeros((maxlen, emb_size))\n",
        "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
        "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
        "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.register_buffer('pos_embedding', pos_embedding)\n",
        "\n",
        "    def forward(self, token_embedding: Tensor):\n",
        "        return self.dropout(token_embedding + self.pos_embedding[:token_embedding.size(0), :])\n",
        "\n",
        "# helper Module to convert tensor of input indices into corresponding tensor of token embeddings\n",
        "class TokenEmbedding(nn.Module):\n",
        "    def __init__(self, vocab_size: int, emb_size):\n",
        "        super(TokenEmbedding, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
        "        self.emb_size = emb_size\n",
        "\n",
        "    def forward(self, tokens: Tensor):\n",
        "        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)\n",
        "\n",
        "# The Network\n",
        "class Seq2SeqTransformer(nn.Module):\n",
        "    def __init__(self,\n",
        "                 num_encoder_layers: int,\n",
        "                 num_decoder_layers: int,\n",
        "                 emb_size: int,\n",
        "                 nhead: int,\n",
        "                 src_vocab_size: int,\n",
        "                 tgt_vocab_size: int,\n",
        "                 dim_feedforward: int = 512,\n",
        "                 dropout: float = 0.1):\n",
        "        super(Seq2SeqTransformer, self).__init__()\n",
        "        self.transformer = Transformer(d_model=emb_size,\n",
        "                                       nhead=nhead,\n",
        "                                       num_encoder_layers=num_encoder_layers,\n",
        "                                       num_decoder_layers=num_decoder_layers,\n",
        "                                       dim_feedforward=dim_feedforward,\n",
        "                                       dropout=dropout)\n",
        "        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n",
        "        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n",
        "        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n",
        "        self.positional_encoding = PositionalEncoding(\n",
        "            emb_size, dropout=dropout)\n",
        "\n",
        "    def forward(self,\n",
        "                src: Tensor,\n",
        "                trg: Tensor,\n",
        "                src_mask: Tensor,\n",
        "                tgt_mask: Tensor,\n",
        "                src_padding_mask: Tensor,\n",
        "                tgt_padding_mask: Tensor,\n",
        "                memory_key_padding_mask: Tensor):\n",
        "        src_emb = self.positional_encoding(self.src_tok_emb(src))\n",
        "        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n",
        "        outs = self.transformer(src_emb, tgt_emb, src_mask, tgt_mask, None,\n",
        "                                src_padding_mask, tgt_padding_mask, memory_key_padding_mask)\n",
        "        return self.generator(outs)\n",
        "\n",
        "    def encode(self, src: Tensor, src_mask: Tensor):\n",
        "        return self.transformer.encoder(self.positional_encoding(\n",
        "                            self.src_tok_emb(src)), src_mask)\n",
        "\n",
        "    def decode(self, tgt: Tensor, memory: Tensor, tgt_mask: Tensor):\n",
        "        return self.transformer.decoder(self.positional_encoding(\n",
        "                          self.tgt_tok_emb(tgt)), memory,\n",
        "                          tgt_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4SbdK3S-aCJP"
      },
      "outputs": [],
      "source": [
        "def generate_square_subsequent_mask(sz):\n",
        "    mask = (torch.triu(torch.ones((sz, sz), device=DEVICE)) == 1).transpose(0, 1)\n",
        "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "    return mask\n",
        "\n",
        "\n",
        "#mask creation for preventing the knowledge of presence of elements in future time steps\n",
        "def create_mask(src, tgt):\n",
        "    src_seq_len = src.shape[0]\n",
        "    tgt_seq_len = tgt.shape[0]\n",
        "\n",
        "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
        "    src_mask = torch.zeros((src_seq_len, src_seq_len),device=DEVICE).type(torch.bool)\n",
        "\n",
        "    src_padding_mask = (src == PAD_IDX).transpose(0, 1)\n",
        "    tgt_padding_mask = (tgt == PAD_IDX).transpose(0, 1)\n",
        "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dR-tgFmjaCJS",
        "outputId": "0e2649ab-0875-4da0-f9dd-fba8832fdeee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60000\n",
            "40000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        }
      ],
      "source": [
        "#hyper-paramerter setting\n",
        "\n",
        "torch.manual_seed(0)\n",
        "\n",
        "SRC_VOCAB_SIZE = len(vocab_transform[SRC_LANGUAGE])\n",
        "TGT_VOCAB_SIZE = len(vocab_transform[TGT_LANGUAGE])\n",
        "print(SRC_VOCAB_SIZE)\n",
        "print(TGT_VOCAB_SIZE)\n",
        "\n",
        "\n",
        "\n",
        "#creating the model with the hyperparams specified as above\n",
        "transformer = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE,\n",
        "                                 NHEAD, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE, FFN_HID_DIM)\n",
        "\n",
        "# initializes the weight matrices of the transformer model using Xavier uniform initialization\n",
        "for p in transformer.parameters():\n",
        "    if p.dim() > 1:\n",
        "        nn.init.xavier_uniform_(p)\n",
        "\n",
        "transformer = transformer.to(DEVICE) #push the model to the device\n",
        "\n",
        "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX) #cross entropy loss\n",
        "\n",
        "optimizer = torch.optim.Adam(transformer.parameters(), lr=lr, betas=betas, eps=eps) #adam optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N2Ter7p3aCJV"
      },
      "outputs": [],
      "source": [
        "'''creating the collate function to be passed in the dataloader which will basically apply\n",
        "this function to every entry of the batch and make the data feedable to the model\n",
        "'''\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "# helper function to club together sequential operations\n",
        "def sequential_transforms(*transforms):\n",
        "    def func(txt_input):\n",
        "        for transform in transforms:\n",
        "            txt_input = transform(txt_input)\n",
        "        return txt_input\n",
        "    return func\n",
        "\n",
        "# function to add BOS/EOS and create tensor for input sequence indices\n",
        "def tensor_transform(token_ids: List[int]):\n",
        "    return torch.cat((torch.tensor([BOS_IDX]),\n",
        "                      torch.tensor(token_ids),\n",
        "                      torch.tensor([EOS_IDX])))\n",
        "\n",
        "# src and tgt language text transforms to convert raw strings into tensors indices\n",
        "text_transform = {}\n",
        "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
        "    text_transform[ln] = sequential_transforms(token_transform[ln], #Tokenization\n",
        "                                               vocab_transform[ln], #Numericalization\n",
        "                                               tensor_transform) # Add BOS/EOS and create tensor\n",
        "\n",
        "\n",
        "# function to collate data samples into batch tensors\n",
        "def collate_fn(batch):\n",
        "    src_batch, tgt_batch = [], []\n",
        "    for src_sample, tgt_sample in batch:\n",
        "        src_batch.append(text_transform[SRC_LANGUAGE](src_sample.rstrip(\"\\n\")))\n",
        "        tgt_batch.append(text_transform[TGT_LANGUAGE](tgt_sample.rstrip(\"\\n\")))\n",
        "\n",
        "    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX)\n",
        "    tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX)\n",
        "    return src_batch, tgt_batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6p-mjV1I3ZLm",
        "outputId": "03c6018d-1705-4c53-e59f-8681b5e1ea9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([36, 16])\n",
            "torch.Size([50, 16])\n",
            "torch.Size([39, 16])\n",
            "torch.Size([40, 16])\n"
          ]
        }
      ],
      "source": [
        "train_iter = MyIterableDataset(train['english'], train['hindi'])\n",
        "train_dataloader = DataLoader(train_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
        "count = 1\n",
        "for src, tgt in train_dataloader:\n",
        "  if count == 5:\n",
        "    break\n",
        "  print(src.shape)\n",
        "  count+=1\n",
        "\n",
        "#checking the shapes of different batches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJxQj2U1IOWo",
        "outputId": "7348e17d-4bd4-4883-e1c2-ada15d36f7e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "115451\n",
            "12828\n"
          ]
        }
      ],
      "source": [
        "ntrain = train.shape[0]\n",
        "neval = eval.shape[0]\n",
        "print(ntrain)\n",
        "print(neval)\n",
        "\n",
        "#total number of samples in the train and eval dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4qutjpTXIkEf",
        "outputId": "ce65d30e-e26a-4275-f409-a4ea4f3a5a42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of train batches  7216\n",
            "number of eval batches  802\n"
          ]
        }
      ],
      "source": [
        "ntrainbatches = int(np.ceil(ntrain/BATCH_SIZE))\n",
        "nevalbatches = int(np.ceil(neval/BATCH_SIZE))\n",
        "print(\"number of train batches \", ntrainbatches)\n",
        "print(\"number of eval batches \", nevalbatches)\n",
        "\n",
        "#total number of batches in the train and eval dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OdhtswLKaCJZ"
      },
      "outputs": [],
      "source": [
        "# Functions for training and evaluation on the whole dataset for one epoch\n",
        "\n",
        "def train_epoch(model, optimizer):\n",
        "    model.train()\n",
        "    losses = 0\n",
        "    train_iter = MyIterableDataset(train['english'], train['hindi'])\n",
        "    train_dataloader = DataLoader(train_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
        "    for src, tgt in train_dataloader:\n",
        "\n",
        "        src = src.to(DEVICE)\n",
        "        tgt = tgt.to(DEVICE)\n",
        "\n",
        "        tgt_input = tgt[:-1, :]\n",
        "\n",
        "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
        "\n",
        "\n",
        "        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        tgt_out = tgt[1:, :]\n",
        "\n",
        "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "        losses += loss.item()\n",
        "\n",
        "    print(\"train losses \", losses)\n",
        "    return losses / ntrainbatches\n",
        "\n",
        "\n",
        "def evaluate(model):\n",
        "    model.eval()\n",
        "    losses = 0\n",
        "\n",
        "\n",
        "    eval_iter = MyIterableDataset(eval['english'], eval['hindi'])\n",
        "    val_dataloader = DataLoader(eval_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
        "\n",
        "\n",
        "    for src, tgt in val_dataloader:\n",
        "        src = src.to(DEVICE)\n",
        "        tgt = tgt.to(DEVICE)\n",
        "\n",
        "        tgt_input = tgt[:-1, :]\n",
        "\n",
        "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
        "\n",
        "        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
        "\n",
        "        tgt_out = tgt[1:, :]\n",
        "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
        "        losses += loss.item()\n",
        "    print(\"validation losses \", losses)\n",
        "    return losses / nevalbatches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NGyQpL0KTirY"
      },
      "outputs": [],
      "source": [
        "!export CUDA_LAUNCH_BLOCKING=1 #might give error some time, just comment out if it does so"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b2o2Vav-4_mw"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rTSyNGN47lW",
        "outputId": "1773d01a-e021-4c42-fb7b-1f7d43998a77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Oct 25 17:10:59 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   69C    P0    30W /  70W |   1333MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "transformerh = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE,\n",
        "                                 NHEAD, 30000, 20000, FFN_HID_DIM)\n",
        "transformerh.load_state_dict(torch.load('/content/drive/My Drive/My Folder1/model_Hindi.pt'))\n"
      ],
      "metadata": {
        "id": "-mDgd0lu4tx1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d3a2e4a-aefd-410a-95ef-bb1eb2a58018"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "transformerg = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE,\n",
        "                                 NHEAD, 30000, 20000, FFN_HID_DIM)\n",
        "transformerg.load_state_dict(torch.load('/content/drive/My Drive/My Folder1/model_Gujarati.pt'))"
      ],
      "metadata": {
        "id": "SIzRYO0b56P9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c6ee4ec-ecc6-4138-8274-6b9005963188"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sdg = transformerg.state_dict()"
      ],
      "metadata": {
        "id": "c5Pnw_oo8KRl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sdh = transformerh.state_dict()"
      ],
      "metadata": {
        "id": "ssDQ_E--8x0A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sd = transformer.state_dict()"
      ],
      "metadata": {
        "id": "Fa4xGGai8zKO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for keys in sdg:\n",
        "  print(sdg[keys].size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FErQjaxb8Dxg",
        "outputId": "0c5746bf-71d7-40db-f965-bd81b5f8547c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1200, 400])\n",
            "torch.Size([1200])\n",
            "torch.Size([400, 400])\n",
            "torch.Size([400])\n",
            "torch.Size([128, 400])\n",
            "torch.Size([128])\n",
            "torch.Size([400, 128])\n",
            "torch.Size([400])\n",
            "torch.Size([400])\n",
            "torch.Size([400])\n",
            "torch.Size([400])\n",
            "torch.Size([400])\n",
            "torch.Size([1200, 400])\n",
            "torch.Size([1200])\n",
            "torch.Size([400, 400])\n",
            "torch.Size([400])\n",
            "torch.Size([128, 400])\n",
            "torch.Size([128])\n",
            "torch.Size([400, 128])\n",
            "torch.Size([400])\n",
            "torch.Size([400])\n",
            "torch.Size([400])\n",
            "torch.Size([400])\n",
            "torch.Size([400])\n",
            "torch.Size([1200, 400])\n",
            "torch.Size([1200])\n",
            "torch.Size([400, 400])\n",
            "torch.Size([400])\n",
            "torch.Size([128, 400])\n",
            "torch.Size([128])\n",
            "torch.Size([400, 128])\n",
            "torch.Size([400])\n",
            "torch.Size([400])\n",
            "torch.Size([400])\n",
            "torch.Size([400])\n",
            "torch.Size([400])\n",
            "torch.Size([1200, 400])\n",
            "torch.Size([1200])\n",
            "torch.Size([400, 400])\n",
            "torch.Size([400])\n",
            "torch.Size([128, 400])\n",
            "torch.Size([128])\n",
            "torch.Size([400, 128])\n",
            "torch.Size([400])\n",
            "torch.Size([400])\n",
            "torch.Size([400])\n",
            "torch.Size([400])\n",
            "torch.Size([400])\n",
            "torch.Size([400])\n",
            "torch.Size([400])\n",
            "torch.Size([1200, 400])\n",
            "torch.Size([1200])\n",
            "torch.Size([400, 400])\n",
            "torch.Size([400])\n",
            "torch.Size([1200, 400])\n",
            "torch.Size([1200])\n",
            "torch.Size([400, 400])\n",
            "torch.Size([400])\n",
            "torch.Size([128, 400])\n",
            "torch.Size([128])\n",
            "torch.Size([400, 128])\n",
            "torch.Size([400])\n",
            "torch.Size([400])\n",
            "torch.Size([400])\n",
            "torch.Size([400])\n",
            "torch.Size([400])\n",
            "torch.Size([400])\n",
            "torch.Size([400])\n",
            "torch.Size([1200, 400])\n",
            "torch.Size([1200])\n",
            "torch.Size([400, 400])\n",
            "torch.Size([400])\n",
            "torch.Size([1200, 400])\n",
            "torch.Size([1200])\n",
            "torch.Size([400, 400])\n",
            "torch.Size([400])\n",
            "torch.Size([128, 400])\n",
            "torch.Size([128])\n",
            "torch.Size([400, 128])\n",
            "torch.Size([400])\n",
            "torch.Size([400])\n",
            "torch.Size([400])\n",
            "torch.Size([400])\n",
            "torch.Size([400])\n",
            "torch.Size([400])\n",
            "torch.Size([400])\n",
            "torch.Size([1200, 400])\n",
            "torch.Size([1200])\n",
            "torch.Size([400, 400])\n",
            "torch.Size([400])\n",
            "torch.Size([1200, 400])\n",
            "torch.Size([1200])\n",
            "torch.Size([400, 400])\n",
            "torch.Size([400])\n",
            "torch.Size([128, 400])\n",
            "torch.Size([128])\n",
            "torch.Size([400, 128])\n",
            "torch.Size([400])\n",
            "torch.Size([400])\n",
            "torch.Size([400])\n",
            "torch.Size([400])\n",
            "torch.Size([400])\n",
            "torch.Size([400])\n",
            "torch.Size([400])\n",
            "torch.Size([1200, 400])\n",
            "torch.Size([1200])\n",
            "torch.Size([400, 400])\n",
            "torch.Size([400])\n",
            "torch.Size([1200, 400])\n",
            "torch.Size([1200])\n",
            "torch.Size([400, 400])\n",
            "torch.Size([400])\n",
            "torch.Size([128, 400])\n",
            "torch.Size([128])\n",
            "torch.Size([400, 128])\n",
            "torch.Size([400])\n",
            "torch.Size([400])\n",
            "torch.Size([400])\n",
            "torch.Size([400])\n",
            "torch.Size([400])\n",
            "torch.Size([400])\n",
            "torch.Size([400])\n",
            "torch.Size([400])\n",
            "torch.Size([400])\n",
            "torch.Size([20000, 400])\n",
            "torch.Size([20000])\n",
            "torch.Size([30000, 400])\n",
            "torch.Size([20000, 400])\n",
            "torch.Size([7000, 1, 400])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for keys in sdg:\n",
        "  print(keys)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8IbRO9g9x_F",
        "outputId": "603f506e-89da-4c9f-e9e1-7c3f8c073fd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "transformer.encoder.layers.0.self_attn.in_proj_weight\n",
            "transformer.encoder.layers.0.self_attn.in_proj_bias\n",
            "transformer.encoder.layers.0.self_attn.out_proj.weight\n",
            "transformer.encoder.layers.0.self_attn.out_proj.bias\n",
            "transformer.encoder.layers.0.linear1.weight\n",
            "transformer.encoder.layers.0.linear1.bias\n",
            "transformer.encoder.layers.0.linear2.weight\n",
            "transformer.encoder.layers.0.linear2.bias\n",
            "transformer.encoder.layers.0.norm1.weight\n",
            "transformer.encoder.layers.0.norm1.bias\n",
            "transformer.encoder.layers.0.norm2.weight\n",
            "transformer.encoder.layers.0.norm2.bias\n",
            "transformer.encoder.layers.1.self_attn.in_proj_weight\n",
            "transformer.encoder.layers.1.self_attn.in_proj_bias\n",
            "transformer.encoder.layers.1.self_attn.out_proj.weight\n",
            "transformer.encoder.layers.1.self_attn.out_proj.bias\n",
            "transformer.encoder.layers.1.linear1.weight\n",
            "transformer.encoder.layers.1.linear1.bias\n",
            "transformer.encoder.layers.1.linear2.weight\n",
            "transformer.encoder.layers.1.linear2.bias\n",
            "transformer.encoder.layers.1.norm1.weight\n",
            "transformer.encoder.layers.1.norm1.bias\n",
            "transformer.encoder.layers.1.norm2.weight\n",
            "transformer.encoder.layers.1.norm2.bias\n",
            "transformer.encoder.layers.2.self_attn.in_proj_weight\n",
            "transformer.encoder.layers.2.self_attn.in_proj_bias\n",
            "transformer.encoder.layers.2.self_attn.out_proj.weight\n",
            "transformer.encoder.layers.2.self_attn.out_proj.bias\n",
            "transformer.encoder.layers.2.linear1.weight\n",
            "transformer.encoder.layers.2.linear1.bias\n",
            "transformer.encoder.layers.2.linear2.weight\n",
            "transformer.encoder.layers.2.linear2.bias\n",
            "transformer.encoder.layers.2.norm1.weight\n",
            "transformer.encoder.layers.2.norm1.bias\n",
            "transformer.encoder.layers.2.norm2.weight\n",
            "transformer.encoder.layers.2.norm2.bias\n",
            "transformer.encoder.layers.3.self_attn.in_proj_weight\n",
            "transformer.encoder.layers.3.self_attn.in_proj_bias\n",
            "transformer.encoder.layers.3.self_attn.out_proj.weight\n",
            "transformer.encoder.layers.3.self_attn.out_proj.bias\n",
            "transformer.encoder.layers.3.linear1.weight\n",
            "transformer.encoder.layers.3.linear1.bias\n",
            "transformer.encoder.layers.3.linear2.weight\n",
            "transformer.encoder.layers.3.linear2.bias\n",
            "transformer.encoder.layers.3.norm1.weight\n",
            "transformer.encoder.layers.3.norm1.bias\n",
            "transformer.encoder.layers.3.norm2.weight\n",
            "transformer.encoder.layers.3.norm2.bias\n",
            "transformer.encoder.norm.weight\n",
            "transformer.encoder.norm.bias\n",
            "transformer.decoder.layers.0.self_attn.in_proj_weight\n",
            "transformer.decoder.layers.0.self_attn.in_proj_bias\n",
            "transformer.decoder.layers.0.self_attn.out_proj.weight\n",
            "transformer.decoder.layers.0.self_attn.out_proj.bias\n",
            "transformer.decoder.layers.0.multihead_attn.in_proj_weight\n",
            "transformer.decoder.layers.0.multihead_attn.in_proj_bias\n",
            "transformer.decoder.layers.0.multihead_attn.out_proj.weight\n",
            "transformer.decoder.layers.0.multihead_attn.out_proj.bias\n",
            "transformer.decoder.layers.0.linear1.weight\n",
            "transformer.decoder.layers.0.linear1.bias\n",
            "transformer.decoder.layers.0.linear2.weight\n",
            "transformer.decoder.layers.0.linear2.bias\n",
            "transformer.decoder.layers.0.norm1.weight\n",
            "transformer.decoder.layers.0.norm1.bias\n",
            "transformer.decoder.layers.0.norm2.weight\n",
            "transformer.decoder.layers.0.norm2.bias\n",
            "transformer.decoder.layers.0.norm3.weight\n",
            "transformer.decoder.layers.0.norm3.bias\n",
            "transformer.decoder.layers.1.self_attn.in_proj_weight\n",
            "transformer.decoder.layers.1.self_attn.in_proj_bias\n",
            "transformer.decoder.layers.1.self_attn.out_proj.weight\n",
            "transformer.decoder.layers.1.self_attn.out_proj.bias\n",
            "transformer.decoder.layers.1.multihead_attn.in_proj_weight\n",
            "transformer.decoder.layers.1.multihead_attn.in_proj_bias\n",
            "transformer.decoder.layers.1.multihead_attn.out_proj.weight\n",
            "transformer.decoder.layers.1.multihead_attn.out_proj.bias\n",
            "transformer.decoder.layers.1.linear1.weight\n",
            "transformer.decoder.layers.1.linear1.bias\n",
            "transformer.decoder.layers.1.linear2.weight\n",
            "transformer.decoder.layers.1.linear2.bias\n",
            "transformer.decoder.layers.1.norm1.weight\n",
            "transformer.decoder.layers.1.norm1.bias\n",
            "transformer.decoder.layers.1.norm2.weight\n",
            "transformer.decoder.layers.1.norm2.bias\n",
            "transformer.decoder.layers.1.norm3.weight\n",
            "transformer.decoder.layers.1.norm3.bias\n",
            "transformer.decoder.layers.2.self_attn.in_proj_weight\n",
            "transformer.decoder.layers.2.self_attn.in_proj_bias\n",
            "transformer.decoder.layers.2.self_attn.out_proj.weight\n",
            "transformer.decoder.layers.2.self_attn.out_proj.bias\n",
            "transformer.decoder.layers.2.multihead_attn.in_proj_weight\n",
            "transformer.decoder.layers.2.multihead_attn.in_proj_bias\n",
            "transformer.decoder.layers.2.multihead_attn.out_proj.weight\n",
            "transformer.decoder.layers.2.multihead_attn.out_proj.bias\n",
            "transformer.decoder.layers.2.linear1.weight\n",
            "transformer.decoder.layers.2.linear1.bias\n",
            "transformer.decoder.layers.2.linear2.weight\n",
            "transformer.decoder.layers.2.linear2.bias\n",
            "transformer.decoder.layers.2.norm1.weight\n",
            "transformer.decoder.layers.2.norm1.bias\n",
            "transformer.decoder.layers.2.norm2.weight\n",
            "transformer.decoder.layers.2.norm2.bias\n",
            "transformer.decoder.layers.2.norm3.weight\n",
            "transformer.decoder.layers.2.norm3.bias\n",
            "transformer.decoder.layers.3.self_attn.in_proj_weight\n",
            "transformer.decoder.layers.3.self_attn.in_proj_bias\n",
            "transformer.decoder.layers.3.self_attn.out_proj.weight\n",
            "transformer.decoder.layers.3.self_attn.out_proj.bias\n",
            "transformer.decoder.layers.3.multihead_attn.in_proj_weight\n",
            "transformer.decoder.layers.3.multihead_attn.in_proj_bias\n",
            "transformer.decoder.layers.3.multihead_attn.out_proj.weight\n",
            "transformer.decoder.layers.3.multihead_attn.out_proj.bias\n",
            "transformer.decoder.layers.3.linear1.weight\n",
            "transformer.decoder.layers.3.linear1.bias\n",
            "transformer.decoder.layers.3.linear2.weight\n",
            "transformer.decoder.layers.3.linear2.bias\n",
            "transformer.decoder.layers.3.norm1.weight\n",
            "transformer.decoder.layers.3.norm1.bias\n",
            "transformer.decoder.layers.3.norm2.weight\n",
            "transformer.decoder.layers.3.norm2.bias\n",
            "transformer.decoder.layers.3.norm3.weight\n",
            "transformer.decoder.layers.3.norm3.bias\n",
            "transformer.decoder.norm.weight\n",
            "transformer.decoder.norm.bias\n",
            "generator.weight\n",
            "generator.bias\n",
            "src_tok_emb.embedding.weight\n",
            "tgt_tok_emb.embedding.weight\n",
            "positional_encoding.pos_embedding\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for keys in sdg:\n",
        "  if keys not in ['generator.weight', 'generator.bias', 'src_tok_emb.embedding.weight','tgt_tok_emb.embedding.weight']:\n",
        "    sd[keys] = (sdh[keys] + sdg[keys]) / 2\n",
        "  else:\n",
        "    sd[keys] = torch.cat((sdh[keys],sdg[keys]),dim=0)"
      ],
      "metadata": {
        "id": "BWdhYm338V90"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for keys in sd:\n",
        "  print(sd[keys].size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UzgBF4qj_cyQ",
        "outputId": "e9d5d973-b28d-43f6-d55d-42e526cc72cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1200, 400])\n",
            "torch.Size([1200])\n",
            "torch.Size([400, 400])\n",
            "torch.Size([400])\n",
            "torch.Size([128, 400])\n",
            "torch.Size([128])\n",
            "torch.Size([400, 128])\n",
            "torch.Size([400])\n",
            "torch.Size([400])\n",
            "torch.Size([400])\n",
            "torch.Size([400])\n",
            "torch.Size([400])\n",
            "torch.Size([1200, 400])\n",
            "torch.Size([1200])\n",
            "torch.Size([400, 400])\n",
            "torch.Size([400])\n",
            "torch.Size([128, 400])\n",
            "torch.Size([128])\n",
            "torch.Size([400, 128])\n",
            "torch.Size([400])\n",
            "torch.Size([400])\n",
            "torch.Size([400])\n",
            "torch.Size([400])\n",
            "torch.Size([400])\n",
            "torch.Size([1200, 400])\n",
            "torch.Size([1200])\n",
            "torch.Size([400, 400])\n",
            "torch.Size([400])\n",
            "torch.Size([128, 400])\n",
            "torch.Size([128])\n",
            "torch.Size([400, 128])\n",
            "torch.Size([400])\n",
            "torch.Size([400])\n",
            "torch.Size([400])\n",
            "torch.Size([400])\n",
            "torch.Size([400])\n",
            "torch.Size([1200, 400])\n",
            "torch.Size([1200])\n",
            "torch.Size([400, 400])\n",
            "torch.Size([400])\n",
            "torch.Size([128, 400])\n",
            "torch.Size([128])\n",
            "torch.Size([400, 128])\n",
            "torch.Size([400])\n",
            "torch.Size([400])\n",
            "torch.Size([400])\n",
            "torch.Size([400])\n",
            "torch.Size([400])\n",
            "torch.Size([400])\n",
            "torch.Size([400])\n",
            "torch.Size([1200, 400])\n",
            "torch.Size([1200])\n",
            "torch.Size([400, 400])\n",
            "torch.Size([400])\n",
            "torch.Size([1200, 400])\n",
            "torch.Size([1200])\n",
            "torch.Size([400, 400])\n",
            "torch.Size([400])\n",
            "torch.Size([128, 400])\n",
            "torch.Size([128])\n",
            "torch.Size([400, 128])\n",
            "torch.Size([400])\n",
            "torch.Size([400])\n",
            "torch.Size([400])\n",
            "torch.Size([400])\n",
            "torch.Size([400])\n",
            "torch.Size([400])\n",
            "torch.Size([400])\n",
            "torch.Size([1200, 400])\n",
            "torch.Size([1200])\n",
            "torch.Size([400, 400])\n",
            "torch.Size([400])\n",
            "torch.Size([1200, 400])\n",
            "torch.Size([1200])\n",
            "torch.Size([400, 400])\n",
            "torch.Size([400])\n",
            "torch.Size([128, 400])\n",
            "torch.Size([128])\n",
            "torch.Size([400, 128])\n",
            "torch.Size([400])\n",
            "torch.Size([400])\n",
            "torch.Size([400])\n",
            "torch.Size([400])\n",
            "torch.Size([400])\n",
            "torch.Size([400])\n",
            "torch.Size([400])\n",
            "torch.Size([1200, 400])\n",
            "torch.Size([1200])\n",
            "torch.Size([400, 400])\n",
            "torch.Size([400])\n",
            "torch.Size([1200, 400])\n",
            "torch.Size([1200])\n",
            "torch.Size([400, 400])\n",
            "torch.Size([400])\n",
            "torch.Size([128, 400])\n",
            "torch.Size([128])\n",
            "torch.Size([400, 128])\n",
            "torch.Size([400])\n",
            "torch.Size([400])\n",
            "torch.Size([400])\n",
            "torch.Size([400])\n",
            "torch.Size([400])\n",
            "torch.Size([400])\n",
            "torch.Size([400])\n",
            "torch.Size([1200, 400])\n",
            "torch.Size([1200])\n",
            "torch.Size([400, 400])\n",
            "torch.Size([400])\n",
            "torch.Size([1200, 400])\n",
            "torch.Size([1200])\n",
            "torch.Size([400, 400])\n",
            "torch.Size([400])\n",
            "torch.Size([128, 400])\n",
            "torch.Size([128])\n",
            "torch.Size([400, 128])\n",
            "torch.Size([400])\n",
            "torch.Size([400])\n",
            "torch.Size([400])\n",
            "torch.Size([400])\n",
            "torch.Size([400])\n",
            "torch.Size([400])\n",
            "torch.Size([400])\n",
            "torch.Size([400])\n",
            "torch.Size([400])\n",
            "torch.Size([40000, 400])\n",
            "torch.Size([40000])\n",
            "torch.Size([60000, 400])\n",
            "torch.Size([40000, 400])\n",
            "torch.Size([7000, 1, 400])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transformer.load_state_dict(sd)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AOWzwcQF_oUe",
        "outputId": "0c374e01-a02f-4e94-bf16-72e0a7ca8000"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VX3UFpM4aCJd",
        "outputId": "ba93bcd1-896a-46db-f9ea-5f40f948029c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:5076: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train losses  16096.675074577332\n",
            "validation losses  1606.6980123519897\n",
            "Epoch: 1, Train loss: 6.026, Val loss: 5.410, Epoch time = 136.833s\n",
            "train losses  14372.425408363342\n",
            "validation losses  1528.2160806655884\n",
            "Epoch: 2, Train loss: 5.381, Val loss: 5.146, Epoch time = 128.537s\n",
            "train losses  13570.745317459106\n",
            "validation losses  1479.1337885856628\n",
            "Epoch: 3, Train loss: 5.081, Val loss: 4.980, Epoch time = 128.961s\n",
            "train losses  12912.93973684311\n",
            "validation losses  1439.1085238456726\n",
            "Epoch: 4, Train loss: 4.834, Val loss: 4.845, Epoch time = 129.875s\n",
            "train losses  12341.223169326782\n",
            "validation losses  1403.7513482570648\n",
            "Epoch: 5, Train loss: 4.620, Val loss: 4.726, Epoch time = 131.267s\n",
            "train losses  11828.317115068436\n",
            "validation losses  1375.5879106521606\n",
            "Epoch: 6, Train loss: 4.428, Val loss: 4.632, Epoch time = 131.106s\n",
            "train losses  11352.510306835175\n",
            "validation losses  1354.818655014038\n",
            "Epoch: 7, Train loss: 4.250, Val loss: 4.562, Epoch time = 130.869s\n",
            "train losses  10924.681138038635\n",
            "validation losses  1342.5096917152405\n",
            "Epoch: 8, Train loss: 4.090, Val loss: 4.520, Epoch time = 130.664s\n",
            "train losses  10510.382575511932\n",
            "validation losses  1332.2947692871094\n",
            "Epoch: 9, Train loss: 3.935, Val loss: 4.486, Epoch time = 130.081s\n",
            "train losses  10127.053121566772\n",
            "validation losses  1331.3322188854218\n",
            "Epoch: 10, Train loss: 3.791, Val loss: 4.483, Epoch time = 130.035s\n",
            "train losses  9764.59593296051\n",
            "validation losses  1332.2804734706879\n"
          ]
        }
      ],
      "source": [
        "#training loop\n",
        "prev_val_loss = 0\n",
        "for epoch in range(1, NUM_EPOCHS+1):\n",
        "    start_time = timer()\n",
        "\n",
        "    train_loss = train_epoch(transformer, optimizer)\n",
        "\n",
        "    end_time = timer()\n",
        "    val_loss = evaluate(transformer)\n",
        "    if epoch == 1:\n",
        "        prev_val_loss = val_loss\n",
        "    else:\n",
        "        e = prev_val_loss - val_loss\n",
        "        if e < 0.001:\n",
        "            break\n",
        "        prev_val_loss = val_loss\n",
        "\n",
        "    print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, \"f\"Epoch time = {(end_time - start_time):.3f}s\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oyWpFUNp3YDn"
      },
      "outputs": [],
      "source": [
        "torch.save(transformer.state_dict(),model_filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SutpsX_3TirY"
      },
      "outputs": [],
      "source": [
        "'''functions for decoding the final output tensor into the english sentence. We have used\n",
        "two types of decoding techniques namely beam search decode and greedy decode. Although\n",
        "we have used only the greedy decode scheme for our purpose for the reason that it takes\n",
        "less '''\n",
        "\n",
        "import heapq\n",
        "import nltk\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "\n",
        "\n",
        "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
        "    src = src.to(DEVICE)\n",
        "    src_mask = src_mask.to(DEVICE)\n",
        "\n",
        "    memory = model.encode(src, src_mask)\n",
        "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n",
        "    for i in range(max_len-1):\n",
        "        memory = memory.to(DEVICE)\n",
        "        tgt_mask = (generate_square_subsequent_mask(ys.size(0))\n",
        "                    .type(torch.bool)).to(DEVICE)\n",
        "        out = model.decode(ys, memory, tgt_mask)\n",
        "        out = out.transpose(0, 1)\n",
        "        prob = model.generator(out[:, -1])\n",
        "        _, next_word = torch.max(prob, dim=1)\n",
        "        next_word = next_word.item()\n",
        "\n",
        "        ys = torch.cat([ys,\n",
        "                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n",
        "        if next_word == EOS_IDX:\n",
        "            break\n",
        "    return ys\n",
        "\n",
        "def beam_search_decode(model, src, src_mask, max_len, start_symbol, beam_size=3):\n",
        "    src = src.to(DEVICE)\n",
        "    src_mask = src_mask.to(DEVICE)\n",
        "\n",
        "    memory = model.encode(src, src_mask)\n",
        "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n",
        "\n",
        "    # Initialize the beam with a single hypothesis\n",
        "    beams = [(0.0, ys)]\n",
        "\n",
        "    # Repeat beam expansion until max_len or EOS is reached\n",
        "    for i in range(max_len-1):\n",
        "        new_beams = []\n",
        "        for score, ys in beams:\n",
        "            # Check if the last token in the sequence is EOS\n",
        "            if ys[-1] == EOS_IDX:\n",
        "                new_beams.append((score, ys))\n",
        "                continue\n",
        "\n",
        "            memory = memory.to(DEVICE)\n",
        "            tgt_mask = (generate_square_subsequent_mask(ys.size(0))\n",
        "                        .type(torch.bool)).to(DEVICE)\n",
        "            tgt_mask = tgt_mask.unsqueeze(0)  # Add a new dimension at index 0\n",
        "            tgt_mask = tgt_mask.repeat(2, tgt_mask.shape[1], tgt_mask.shape[1])\n",
        "            print(ys.unsqueeze(0).shape, memory.squeeze(1).shape, tgt_mask.shape)\n",
        "            out = model.decode(ys, memory, tgt_mask)\n",
        "            out = out.squeeze(0)\n",
        "            prob = model.generator(out[-1])\n",
        "            top_probs, top_idxs = torch.topk(prob, beam_size)\n",
        "\n",
        "            # Expand the beam with each possible next token\n",
        "            for j in range(beam_size):\n",
        "                next_word = top_idxs[j].item()\n",
        "                score_j = score + top_probs[j].item()\n",
        "                p = torch.tensor([next_word]).type_as(src.data)\n",
        "                p = p.unsqueeze(0)\n",
        "                print(ys.shape, p.shape)\n",
        "                ys_j = torch.cat([ys, p], dim=0)\n",
        "                new_beams.append((score_j, ys_j))\n",
        "\n",
        "        # Keep only the top beam_size hypotheses\n",
        "        beams = heapq.nlargest(beam_size, new_beams, key=lambda x: x[0])\n",
        "\n",
        "    # Return the hypothesis with the highest score\n",
        "    return beams[0][1]\n",
        "\n",
        "\n",
        "# actual function to translate input sentence into target language\n",
        "def translate(model: torch.nn.Module, src_sentence: str):\n",
        "    model.eval()\n",
        "    src = text_transform[SRC_LANGUAGE](src_sentence).view(-1, 1)\n",
        "    num_tokens = src.shape[0]\n",
        "    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
        "    tgt_tokens = greedy_decode(\n",
        "        model,  src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX).flatten()\n",
        "    return \" \".join(vocab_transform[TGT_LANGUAGE].lookup_tokens(list(tgt_tokens.cpu().numpy()))).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i0oLOnLtaCJe"
      },
      "outputs": [],
      "source": [
        "#example of translation\n",
        "# print(translate(transformer, \"ईमान लाओ और उसके रसूल के साथ होकर जिहाद करो\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXl_MIPuj7Y1",
        "outputId": "1806bac2-f526-40f6-c954-d4aa4657ee08"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ],
      "source": [
        "transformer.load_state_dict(torch.load(model_filename))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hdo5TXHmZlRd",
        "outputId": "88e4dcee-0173-44f9-9e84-f55fc3965197"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "કાપ્પિલ બીચનું નજીકનું રેલવેસ્ટેશન કાસરગોડ , ‍‍‍૧૨ કિલોમીટર દૂર છે .  <unk> <unk> <unk> The <unk> british <unk> breathed branched branched breathed branched breathed branched branched breathed branched\n"
          ]
        }
      ],
      "source": [
        "#checking whether the loaded model is same as the transformer\n",
        "print(final_test_data['sentence'][25], translate(transformer, final_test_data['sentence'][25]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "uNkUYQnsTirZ",
        "outputId": "14def29a-457e-400c-873d-866ab553bacf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'calculation of bleu score , uncomment the following code snippet and change the\\nhypothesis and reference sentence data in the corresponding fields to calculate the\\ncorpus bleu score'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 77
        }
      ],
      "source": [
        "'''calculation of bleu score , uncomment the following code snippet and change the\n",
        "hypothesis and reference sentence data in the corresponding fields to calculate the\n",
        "corpus bleu score'''\n",
        "\n",
        "# from torchtext.data.metrics import bleu_score\n",
        "# actual = [token_transform['hi'](sentence) for sentence in eval['english'][:2000]]\n",
        "# prediction = [token_transform['en'](translate(transformer, sentence)) for sentence in eval['hindi'][:2000]]\n",
        "# Compute individual n-gram scores and their geometric mean\n",
        "# BLEU-4\n",
        "\n",
        "# print(f\"BLEU score: {score: f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "75jCKMD8TirZ"
      },
      "outputs": [],
      "source": [
        "#saving the predicted answers of the final_test_data\n",
        "count = 0\n",
        "with open('temp.txt', 'w', encoding = 'utf-8') as f:\n",
        "  for sentence in final_test_data['sentence']:\n",
        "    translated = translate(transformer, sentence)\n",
        "    # print(type(translated))\n",
        "    count+=1\n",
        "    f.write(translated + '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBjPsM6eeCAu",
        "outputId": "e8d027d1-3724-44a1-e753-e174dbb3dcb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6783\n",
            "6783\n"
          ]
        }
      ],
      "source": [
        "print(len(final_test_data['sentence']))\n",
        "print(count)\n",
        "\n",
        "#checking the count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W7UjUl7_pSdt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77666888-80c4-4436-9d07-1352b9685dc1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6783\n"
          ]
        }
      ],
      "source": [
        "c = 0\n",
        "with open(answer_filename, 'r', encoding = 'utf-8') as f:\n",
        "  for line in f:\n",
        "    c+=1\n",
        "print(c)\n",
        "\n",
        "#rechecking the count by loading the answer.txt"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}