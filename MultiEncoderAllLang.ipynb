{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5-CIb-pub_0F"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from typing import Iterable, List\n",
        "import math\n",
        "from tempfile import TemporaryDirectory\n",
        "from typing import Tuple\n",
        "from torch import nn, Tensor\n",
        "from torch.nn import TransformerEncoder, TransformerEncoderLayer,TransformerDecoder, TransformerDecoderLayer\n",
        "from torch.utils.data import Dataset, IterableDataset, DataLoader, TensorDataset\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch import Tensor\n",
        "from torch.nn import Transformer\n",
        "import math\n",
        "from timeit import default_timer as timer\n",
        "\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu') #set the device as GPU if available"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jok77llycOGB"
      },
      "outputs": [],
      "source": [
        "EMB_SIZE = 400\n",
        "NHEAD = 2\n",
        "FFN_HID_DIM = 512\n",
        "BATCH_SIZE = 16\n",
        "NUM_ENCODER_LAYERS = 4\n",
        "NUM_DECODER_LAYERS = 4\n",
        "lr = 0.0001\n",
        "betas = (0.9, 0.98)\n",
        "eps = 1e-9\n",
        "NUM_EPOCHS = 36 #the result given will come if NUM_EPOCHS is set to 36.\n",
        "split_size = 0.1\n",
        "\n",
        "SRC_LANGUAGE1 = 'Bengali'\n",
        "SRC_LANGUAGE2 = 'Gujarati'\n",
        "SRC_LANGUAGE3 = 'Hindi'\n",
        "SRC_LANGUAGE4 = 'Kannada'\n",
        "SRC_LANGUAGE5 = 'Malayalam'\n",
        "SRC_LANGUAGE6 = 'Tamil'\n",
        "SRC_LANGUAGE7 = 'Telgu'\n",
        "TGT_LANGUAGE = 'English'\n",
        "\n",
        "# vocab_size = {}\n",
        "# vocab_size[SRC_LANGUAGE] = 7000\n",
        "# vocab_size[TGT_LANGUAGE] = 7000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tM_1MYZAaEHF",
        "outputId": "10152a5a-0cfe-4508-ff7a-6f19a24d3bcf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#uncomment the following to mount while using colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h_wJIlrqcQgO"
      },
      "outputs": [],
      "source": [
        "!mkdir -p \"/content/drive/My Drive/My Folder\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def swap_columns(df, col1, col2):\n",
        "    col_list = list(df.columns)\n",
        "    x, y = col_list.index(col1), col_list.index(col2)\n",
        "    col_list[y], col_list[x] = col_list[x], col_list[y]\n",
        "    df = df[col_list]\n",
        "    return df"
      ],
      "metadata": {
        "id": "i4Gfu_doY_W_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHFZbqbwc-hf",
        "outputId": "ed71dea0-f2a0-47cf-f105-55c8ecc6a4bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                             English  \\\n",
            "0  The Bird Sanctuary of Tettekkad Idukki is worl...   \n",
            "1  The exam was taken of students after learning ...   \n",
            "2  While the work was completed in 1336 CE, the p...   \n",
            "3  The merchants probably donated to the monaster...   \n",
            "4  Rice is the only starch which is not responsib...   \n",
            "\n",
            "                                             Bengali  \n",
            "0  তট্টেক্কাড়ুতে অনেক প্রজাতির পাখি ছাড়াও ২৮ প্...  \n",
            "1  আমাদের দেশে প্রাচীনকালে বিদ্যা শেখানোর পরে বিদ...  \n",
            "2  ১৩৩৬ খ্রিষ্টাব্দে কাজটি সম্পন্ন হলেও, পৃথ্বীরা...  \n",
            "3  ব্যবসায়ীরা সম্ভবত মঠগুলিতে দান করতেন, কারণ এই...  \n",
            "4   বাতই এক মাত্র স্টার্চ যেটা গ্যাস সৃষ্টি করে না ׀  \n"
          ]
        }
      ],
      "source": [
        "#loading data from the desired directory\n",
        "DATA_PATH = '/content/drive/MyDrive/Machine_Translation_Data/English_'+SRC_LANGUAGE1+'.csv'\n",
        "# TEST_PATH = '/kaggle/input/cs779-mt/eng_Hindi_data_dev_X.csv'\n",
        "FINAL_TEST_DATA = '/content/drive/MyDrive/Machine_Translation_Data/English_'+SRC_LANGUAGE1+'_Test.csv'\n",
        "data1 = pd.read_csv(DATA_PATH, header = None)\n",
        "data1.columns = [SRC_LANGUAGE1, TGT_LANGUAGE]\n",
        "\n",
        "# test = pd.read_csv(TEST_PATH, header = None)\n",
        "# test.columns = ['sentence']\n",
        "final_test_data1 = pd.read_csv(FINAL_TEST_DATA, header = None)\n",
        "final_test_data1.columns = ['sentence']\n",
        "# data.head()\n",
        "\n",
        "\n",
        "data1 = swap_columns(data1, SRC_LANGUAGE1, TGT_LANGUAGE)\n",
        "print(data1.head())\n",
        "\n",
        "\n",
        "data1[TGT_LANGUAGE] = data1[TGT_LANGUAGE].apply(str)\n",
        "data1[SRC_LANGUAGE1] = data1[SRC_LANGUAGE1].apply(str)\n",
        "final_test_data1['sentence'] = final_test_data1['sentence'].apply(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5eb4aca5-598c-4a8d-f59c-24f68ec88d65",
        "id": "bubF38QnDSGf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                             English  \\\n",
            "0  Aromatic plants and spices such as pepper, gin...   \n",
            "1  Find all blood banks having atleast 1 units of...   \n",
            "2  His Ford sedan was sighted via CCTV footage in...   \n",
            "3  If the Jain tradition about Chandragupta endin...   \n",
            "4  Marking out the land and weighing the seed int...   \n",
            "\n",
            "                                            Gujarati  \n",
            "0  મરી, આદુ, એલચી અને હળદર જેવા સુગંધિત છોડ અને મ...  \n",
            "1  ઇન્દોર જિલ્લાની તમામ બ્લડ બેંકમાંથી ઓછામાં ઓછા...  \n",
            "2  મેલબોર્નમાં તેના ગુમ થયા પછીના દિવસોમાં તેની ફ...  \n",
            "3  જો ચંદ્રગુપ્તએ કર્ણાટકમાં ત્યાગ તરીકે પોતાનું ...  \n",
            "4  જમીન પર નિશાન કરવા અને બીજને યોગ્ય ભાર કે વજન ...  \n"
          ]
        }
      ],
      "source": [
        "#loading data from the desired directory\n",
        "DATA_PATH = '/content/drive/MyDrive/Machine_Translation_Data/English_'+SRC_LANGUAGE2+'.csv'\n",
        "# TEST_PATH = '/kaggle/input/cs779-mt/eng_Hindi_data_dev_X.csv'\n",
        "FINAL_TEST_DATA = '/content/drive/MyDrive/Machine_Translation_Data/English_'+SRC_LANGUAGE2+'_Test.csv'\n",
        "data2 = pd.read_csv(DATA_PATH, header = None)\n",
        "data2.columns = [SRC_LANGUAGE2, TGT_LANGUAGE]\n",
        "\n",
        "# test = pd.read_csv(TEST_PATH, header = None)\n",
        "# test.columns = ['sentence']\n",
        "final_test_data2 = pd.read_csv(FINAL_TEST_DATA, header = None)\n",
        "final_test_data2.columns = ['sentence']\n",
        "# data.head()\n",
        "\n",
        "\n",
        "data2 = swap_columns(data2, SRC_LANGUAGE2, TGT_LANGUAGE)\n",
        "print(data2.head())\n",
        "\n",
        "\n",
        "data2[TGT_LANGUAGE] = data2[TGT_LANGUAGE].apply(str)\n",
        "data2[SRC_LANGUAGE2] = data2[SRC_LANGUAGE2].apply(str)\n",
        "final_test_data2['sentence'] = final_test_data2['sentence'].apply(str)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#loading data from the desired directory\n",
        "DATA_PATH = '/content/drive/MyDrive/Machine_Translation_Data/English_'+SRC_LANGUAGE3+'.csv'\n",
        "# TEST_PATH = '/kaggle/input/cs779-mt/eng_Hindi_data_dev_X.csv'\n",
        "FINAL_TEST_DATA = '/content/drive/MyDrive/Machine_Translation_Data/English_'+SRC_LANGUAGE3+'_Test.csv'\n",
        "data3 = pd.read_csv(DATA_PATH, header = None)\n",
        "data3.columns = [SRC_LANGUAGE3, TGT_LANGUAGE]\n",
        "\n",
        "# test = pd.read_csv(TEST_PATH, header = None)\n",
        "# test.columns = ['sentence']\n",
        "final_test_data3 = pd.read_csv(FINAL_TEST_DATA, header = None)\n",
        "final_test_data3.columns = ['sentence']\n",
        "# data.head()\n",
        "\n",
        "\n",
        "data3 = swap_columns(data3, SRC_LANGUAGE3, TGT_LANGUAGE)\n",
        "print(data3.head())\n",
        "\n",
        "\n",
        "data3[TGT_LANGUAGE] = data3[TGT_LANGUAGE].apply(str)\n",
        "data3[SRC_LANGUAGE3] = data3[SRC_LANGUAGE3].apply(str)\n",
        "final_test_data3['sentence'] = final_test_data3['sentence'].apply(str)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CAGgIBpWXE-J",
        "outputId": "dc17f05d-f68d-432e-a414-41637bc885eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                             English  \\\n",
            "0  High blood pressure , coronary thrombosis dise...   \n",
            "1                               So, let us see that.   \n",
            "2                           My path is this itself .   \n",
            "3  This has helped people to function effectively...   \n",
            "4  Wherever possible, early admission to hospital...   \n",
            "\n",
            "                                               Hindi  \n",
            "0  खर्राटों से उच्च रक्‍तचाप , कोरोनरी थ्राम्बोसि...  \n",
            "1                    तो, चलिए हम इस पर गौर करते हैं।  \n",
            "2                                मेरा मार्ग यही है ।  \n",
            "3  यह शरीर की तनावमुक्ति की अवस्था को एक पर्दे मे...  \n",
            "4  उन्माद या गंभीर अवसाद के रोगी को जहाँ कहीं भी ...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#loading data from the desired directory\n",
        "DATA_PATH = '/content/drive/MyDrive/Machine_Translation_Data/English_'+SRC_LANGUAGE4+'.csv'\n",
        "# TEST_PATH = '/kaggle/input/cs779-mt/eng_Hindi_data_dev_X.csv'\n",
        "FINAL_TEST_DATA = '/content/drive/MyDrive/Machine_Translation_Data/English_'+SRC_LANGUAGE4+'_Test.csv'\n",
        "data4 = pd.read_csv(DATA_PATH, header = None)\n",
        "data4.columns = [SRC_LANGUAGE4, TGT_LANGUAGE]\n",
        "\n",
        "# test = pd.read_csv(TEST_PATH, header = None)\n",
        "# test.columns = ['sentence']\n",
        "final_test_data4 = pd.read_csv(FINAL_TEST_DATA, header = None)\n",
        "final_test_data4.columns = ['sentence']\n",
        "# data.head()\n",
        "\n",
        "\n",
        "data4 = swap_columns(data4, SRC_LANGUAGE4, TGT_LANGUAGE)\n",
        "print(data4.head())\n",
        "\n",
        "\n",
        "data4[TGT_LANGUAGE] = data4[TGT_LANGUAGE].apply(str)\n",
        "data4[SRC_LANGUAGE4] = data4[SRC_LANGUAGE4].apply(str)\n",
        "final_test_data4['sentence'] = final_test_data4['sentence'].apply(str)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ozybUGPNXav7",
        "outputId": "c7267037-9690-46e6-bbbb-e4e165c7edab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                             English  \\\n",
            "0  At the place of lone market he has considered ...   \n",
            "1  The pure water coming from inside the feet of ...   \n",
            "2  This cave is 4.26 metres long and 3.20 metres ...   \n",
            "3          add tomorrows dinner date to the calendar   \n",
            "4                  is there a article on polar bears   \n",
            "\n",
            "                                             Kannada  \n",
            "0  ಅವರು ಒಂದೇ ಮಾರುಕಟ್ಟೆಯ ಸ್ಥಳದಲ್ಲಿ ಸಮೀಪದ ಐದು ಮಾರು...  \n",
            "1  ಮಾತೆಯ ಚರಣಗಳಿಂದ ಬರುತ್ತಿರುವ ಪವಿತ್ರ ಜಲ ನಿರ್ಗಮನ ದ್...  \n",
            "2  ಈ ಗುಹೆ 4.26 ಮೀಟರ್ ಉದ್ದ ಮತ್ತು 3.20 ಮೀಟರ್‌ ಅಗಲ...  \n",
            "3         ಕ್ಯಾಲೆಂಡರ್‌ಗೆ ನಾಳೆಯ ಊಟದ ದಿನಾಂಕವನ್ನು ಸೇರಿಸಿ  \n",
            "4                        ಹಿಮಕರಡಿಗಳ ಕುರಿತು ಲೇಖನವಿದೆಯೇ  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#loading data from the desired directory\n",
        "DATA_PATH = '/content/drive/MyDrive/Machine_Translation_Data/English_'+SRC_LANGUAGE5+'.csv'\n",
        "# TEST_PATH = '/kaggle/input/cs779-mt/eng_Hindi_data_dev_X.csv'\n",
        "FINAL_TEST_DATA = '/content/drive/MyDrive/Machine_Translation_Data/English_'+SRC_LANGUAGE5+'_Test.csv'\n",
        "data5 = pd.read_csv(DATA_PATH, header = None)\n",
        "data5.columns = [SRC_LANGUAGE5, TGT_LANGUAGE]\n",
        "\n",
        "# test = pd.read_csv(TEST_PATH, header = None)\n",
        "# test.columns = ['sentence']\n",
        "final_test_data5 = pd.read_csv(FINAL_TEST_DATA, header = None)\n",
        "final_test_data5.columns = ['sentence']\n",
        "# data.head()\n",
        "\n",
        "data5 = swap_columns(data5, SRC_LANGUAGE5, TGT_LANGUAGE)\n",
        "print(data5.head())\n",
        "\n",
        "\n",
        "data5[TGT_LANGUAGE] = data5[TGT_LANGUAGE].apply(str)\n",
        "data5[SRC_LANGUAGE5] = data5[SRC_LANGUAGE5].apply(str)\n",
        "final_test_data5['sentence'] = final_test_data5['sentence'].apply(str)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnRx4yHqX3wy",
        "outputId": "152c527e-b1a8-4c2c-b951-6ad9dcad6c87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                             English  \\\n",
            "0  The demand for perfumed oils obtained naturall...   \n",
            "1  Other than this it is necessary to keep having...   \n",
            "2  By drinking water and eating food from the sam...   \n",
            "3  In the other chakuti above that also , which i...   \n",
            "4  The inscription records the lineage and buildi...   \n",
            "\n",
            "                                           Malayalam  \n",
            "0  പ്രാകൃതിക രൂപത്തില്‍ ചെടികളില്‍ നിന്നും ലഭ്യമാ...  \n",
            "1  ഇതിനു പുറമെ നാരുള്ള ഭക്ഷണം , പഴച്ചാറുകള്‍ എന്ന...  \n",
            "2  അണുബാധയുള്ള രോഗികള്‍ ഉപയോഗിച്ച പാത്രങ്ങളില്‍ വ...  \n",
            "3  ആദ്യത്തേതില്‍ നിന്ന് ചെറുതായ ചകൂട്ടില്‍ നാലുവശ...  \n",
            "4  നാലാം നൂറ്റാണ്ടിലേയും അഞ്ചാം നൂറ്റാണ്ടിലേയും സ...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#loading data from the desired directory\n",
        "DATA_PATH = '/content/drive/MyDrive/Machine_Translation_Data/English_'+SRC_LANGUAGE6+'.csv'\n",
        "# TEST_PATH = '/kaggle/input/cs779-mt/eng_Hindi_data_dev_X.csv'\n",
        "FINAL_TEST_DATA = '/content/drive/MyDrive/Machine_Translation_Data/English_'+SRC_LANGUAGE6+'_Test.csv'\n",
        "data6 = pd.read_csv(DATA_PATH, header = None)\n",
        "data6.columns = [SRC_LANGUAGE6, TGT_LANGUAGE]\n",
        "\n",
        "# test = pd.read_csv(TEST_PATH, header = None)\n",
        "# test.columns = ['sentence']\n",
        "final_test_data6 = pd.read_csv(FINAL_TEST_DATA, header = None)\n",
        "final_test_data6.columns = ['sentence']\n",
        "# data.head()\n",
        "\n",
        "\n",
        "data6 = swap_columns(data6, SRC_LANGUAGE6, TGT_LANGUAGE)\n",
        "print(data6.head())\n",
        "\n",
        "\n",
        "data6[TGT_LANGUAGE] = data6[TGT_LANGUAGE].apply(str)\n",
        "data6[SRC_LANGUAGE6] = data6[SRC_LANGUAGE6].apply(str)\n",
        "final_test_data6['sentence'] = final_test_data6['sentence'].apply(str)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w78i38rJYPuu",
        "outputId": "7f0576c4-ff85-4435-86ab-a0aa39432734"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                             English  \\\n",
            "0                 Fennel is a crop of cold climate .   \n",
            "1  Besides his father he took the education in mu...   \n",
            "2  Shanker, is perhaps the best place to eat in A...   \n",
            "3  Major institutions of higher education are NIT...   \n",
            "4  A Nath Yogi ascetic told him that there were m...   \n",
            "\n",
            "                                               Tamil  \n",
            "0  சோம்பு குளிர்ச்சியான பருவநிலை கொண்ட பயிர் ஆகும் .  \n",
            "1  அவர் தன் தந்தையை தவிரவும் தன் சித்தப்பா துர்கா...  \n",
            "2  1. அகர்டாலாவில் குறிப்பாக வங்காள வகைகளில் திரி...  \n",
            "3  என்ஐடி ஸ்ரீநகர், ஐ.ஐ.டி ஜம்மு, ஐ.ஐ.எம் ஜம்மு, ...  \n",
            "4  சித்த மார்க்க துறவி ஒருவர் சிங்களத் தீவில் பல ...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#loading data from the desired directory\n",
        "DATA_PATH = '/content/drive/MyDrive/Machine_Translation_Data/English_'+SRC_LANGUAGE7+'.csv'\n",
        "# TEST_PATH = '/kaggle/input/cs779-mt/eng_Hindi_data_dev_X.csv'\n",
        "FINAL_TEST_DATA = '/content/drive/MyDrive/Machine_Translation_Data/English_'+SRC_LANGUAGE7+'_Test.csv'\n",
        "data7 = pd.read_csv(DATA_PATH, header = None)\n",
        "data7.columns = [SRC_LANGUAGE7, TGT_LANGUAGE]\n",
        "\n",
        "# test = pd.read_csv(TEST_PATH, header = None)\n",
        "# test.columns = ['sentence']\n",
        "final_test_data7 = pd.read_csv(FINAL_TEST_DATA, header = None)\n",
        "final_test_data7.columns = ['sentence']\n",
        "# data.head()\n",
        "\n",
        "data7 = swap_columns(data7, SRC_LANGUAGE7, TGT_LANGUAGE)\n",
        "print(data7.head())\n",
        "\n",
        "\n",
        "data7[TGT_LANGUAGE] = data7[TGT_LANGUAGE].apply(str)\n",
        "data7[SRC_LANGUAGE7] = data7[SRC_LANGUAGE7].apply(str)\n",
        "final_test_data7['sentence'] = final_test_data7['sentence'].apply(str)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uje3IbUXYQUO",
        "outputId": "e7019e67-a790-4e04-e410-10303989cd62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                             English  \\\n",
            "0  This is the lowest part of the Cardamom Hills ...   \n",
            "1  If paying in cash, always insert your coins fi...   \n",
            "2  Some chromosomes like 5 , 11 , 18 , 19 and X h...   \n",
            "3  The native people of Uttarakhand are generally...   \n",
            "4  On 17 June 1608, he married Koka Kumari Begum,...   \n",
            "\n",
            "                                               Telgu  \n",
            "0  ఇడుక్కి జలాశయం ఉన్న ఉత్తరం వైపు వాలుగా ఉన్న ఏల...  \n",
            "1  నగదు రూపంలో చెల్లిస్తే, ఎల్లప్పుడూ మొదట మీ నాణ...  \n",
            "2  కొన్ని క్రోమోజోమ్‍లు అవి 5 , 11 , 18 , 19 మరియ...  \n",
            "3  ఉత్తరాఖండ్ స్థానిక ప్రజలను సాధారణంగా ఉత్తరాఖండ...  \n",
            "4  1608 జూన్ 17న ఆతడు అంబర్ యువరాజైన జగత్ సింగ్ ప...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yF7E3Wan9TJg",
        "outputId": "0f7a7c2e-f2d5-48cf-bbb7-e6bf5299b324"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'indic_nlp_library'...\n",
            "remote: Enumerating objects: 1399, done.\u001b[K\n",
            "remote: Counting objects: 100% (180/180), done.\u001b[K\n",
            "remote: Compressing objects: 100% (57/57), done.\u001b[K\n",
            "remote: Total 1399 (delta 135), reused 147 (delta 120), pack-reused 1219\u001b[K\n",
            "Receiving objects: 100% (1399/1399), 9.57 MiB | 13.24 MiB/s, done.\n",
            "Resolving deltas: 100% (745/745), done.\n",
            "Cloning into 'indic_nlp_resources'...\n",
            "remote: Enumerating objects: 139, done.\u001b[K\n",
            "remote: Counting objects: 100% (13/13), done.\u001b[K\n",
            "remote: Compressing objects: 100% (13/13), done.\u001b[K\n",
            "remote: Total 139 (delta 2), reused 2 (delta 0), pack-reused 126\u001b[K\n",
            "Receiving objects: 100% (139/139), 149.77 MiB | 39.11 MiB/s, done.\n",
            "Resolving deltas: 100% (53/53), done.\n",
            "Collecting Morfessor\n",
            "  Downloading Morfessor-2.0.6-py3-none-any.whl (35 kB)\n",
            "Installing collected packages: Morfessor\n",
            "Successfully installed Morfessor-2.0.6\n"
          ]
        }
      ],
      "source": [
        "!git clone \"https://github.com/anoopkunchukuttan/indic_nlp_library\"\n",
        "!git clone https://github.com/anoopkunchukuttan/indic_nlp_resources.git\n",
        "!pip install Morfessor\n",
        "# The path to the local git repo for Indic NLP library\n",
        "INDIC_NLP_LIB_HOME=r\"/content/indic_nlp_library\"\n",
        "\n",
        "# The path to the local git repo for Indic NLP Resources\n",
        "INDIC_NLP_RESOURCES=\"/content/indic_nlp_resources\"\n",
        "\n",
        "import sys\n",
        "sys.path.append(r'{}'.format(INDIC_NLP_LIB_HOME))\n",
        "from indicnlp import common\n",
        "common.set_resources_path(INDIC_NLP_RESOURCES)\n",
        "from indicnlp import loader\n",
        "loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "ue7w-tQ63p9y",
        "outputId": "4798bac2-c023-4b23-f9e8-94eb692f72e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(61963, 2)\n",
            "(6885, 2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             English  \\\n",
              "0  Subarnameru Temple is situated in Sonepur town...   \n",
              "1  Bonsai plants are planted in pot , whose branc...   \n",
              "2                              november event delete   \n",
              "3  save event for five p. m. to six p. m. on marc...   \n",
              "4  Madhya Pradesh has ceaseless heterogeneity to ...   \n",
              "\n",
              "                                             Bengali  \n",
              "0  সুবর্ণমেরু মন্দির ভারতের ওড়িশা রাজ্যের সুবর্ণ...  \n",
              "1  বনসাই গাছকে গামলায় লাগানো হয় , শাখা ও শিকড়কে ...  \n",
              "2                        নভেম্বরের ইভেন্ট ডিলিট করুন  \n",
              "3  আঠারোই মার্চে সন্ধ্যা পাঁচটা থেকে সন্ধ্যা ছ-টা...  \n",
              "4  মধ্য প্রদেশে পর্যটনকারীদের জন্য অন্তহীন বৈবিধ্...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e2c4f2e4-b48a-4b61-a943-a3d44a5cbd15\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English</th>\n",
              "      <th>Bengali</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Subarnameru Temple is situated in Sonepur town...</td>\n",
              "      <td>সুবর্ণমেরু মন্দির ভারতের ওড়িশা রাজ্যের সুবর্ণ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Bonsai plants are planted in pot , whose branc...</td>\n",
              "      <td>বনসাই গাছকে গামলায় লাগানো হয় , শাখা ও শিকড়কে ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>november event delete</td>\n",
              "      <td>নভেম্বরের ইভেন্ট ডিলিট করুন</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>save event for five p. m. to six p. m. on marc...</td>\n",
              "      <td>আঠারোই মার্চে সন্ধ্যা পাঁচটা থেকে সন্ধ্যা ছ-টা...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Madhya Pradesh has ceaseless heterogeneity to ...</td>\n",
              "      <td>মধ্য প্রদেশে পর্যটনকারীদের জন্য অন্তহীন বৈবিধ্...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e2c4f2e4-b48a-4b61-a943-a3d44a5cbd15')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e2c4f2e4-b48a-4b61-a943-a3d44a5cbd15 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e2c4f2e4-b48a-4b61-a943-a3d44a5cbd15');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ec3586d4-6f80-4ba2-a352-86f783e4949b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ec3586d4-6f80-4ba2-a352-86f783e4949b')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ec3586d4-6f80-4ba2-a352-86f783e4949b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "#train test split using sklearn\n",
        "train1, eval1 = train_test_split(data1, test_size = split_size, random_state = 42)\n",
        "train1 = train1.reset_index(drop = True)\n",
        "eval1 = eval1.reset_index(drop = True)\n",
        "print(train1.shape)\n",
        "print(eval1.shape)\n",
        "train1.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#train test split using sklearn\n",
        "train2, eval2 = train_test_split(data2, test_size = split_size, random_state = 42)\n",
        "train2 = train2.reset_index(drop = True)\n",
        "eval2 = eval2.reset_index(drop = True)\n",
        "print(train2.shape)\n",
        "print(eval2.shape)\n",
        "train2.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "K_xpaWE0okcs",
        "outputId": "3f046fed-fcbb-47b2-d6ab-288cff499c86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(42733, 2)\n",
            "(4749, 2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             English  \\\n",
              "0  Was I credited more than Rs. ₹ 3,510 from anyo...   \n",
              "1  The only aircraft of Bhutan B.E.D. 146 - 100 h...   \n",
              "2  Kolthari' and 'Angathari' include all forms of...   \n",
              "3  Because of improper development of the hip bon...   \n",
              "4  If you have little - bit of common sense , and...   \n",
              "\n",
              "                                            Gujarati  \n",
              "0  શું ગત ૧૫ ડેઝ ૧૫ દિવસ દરમિયાન કોઈ દ્વારા રૂપિય...  \n",
              "1  ભૂતાનનું એકમાત્ર એરક્રાફટ બી.એ.ઈ. ૧૪૬ - ૧૦૦ બે...  \n",
              "2  કોલથારા અને અંગથારા એ શસ્ત્રો લડાઈના દરેક સ્વર...  \n",
              "3  થાપાનું હાડકું અને ગર્ભાશયનો વિકાસ યોગ્ય રીતે ...  \n",
              "4  થોડીક સામાન્ય બુદ્ધિ , થોડીક સહનશીલતા , જો આ ત...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-df7230ad-61a9-417e-8488-20fc27439558\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English</th>\n",
              "      <th>Gujarati</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Was I credited more than Rs. ₹ 3,510 from anyo...</td>\n",
              "      <td>શું ગત ૧૫ ડેઝ ૧૫ દિવસ દરમિયાન કોઈ દ્વારા રૂપિય...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The only aircraft of Bhutan B.E.D. 146 - 100 h...</td>\n",
              "      <td>ભૂતાનનું એકમાત્ર એરક્રાફટ બી.એ.ઈ. ૧૪૬ - ૧૦૦ બે...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Kolthari' and 'Angathari' include all forms of...</td>\n",
              "      <td>કોલથારા અને અંગથારા એ શસ્ત્રો લડાઈના દરેક સ્વર...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Because of improper development of the hip bon...</td>\n",
              "      <td>થાપાનું હાડકું અને ગર્ભાશયનો વિકાસ યોગ્ય રીતે ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>If you have little - bit of common sense , and...</td>\n",
              "      <td>થોડીક સામાન્ય બુદ્ધિ , થોડીક સહનશીલતા , જો આ ત...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-df7230ad-61a9-417e-8488-20fc27439558')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-df7230ad-61a9-417e-8488-20fc27439558 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-df7230ad-61a9-417e-8488-20fc27439558');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-46f9888d-a4bc-4dd3-9a78-33ec38595a59\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-46f9888d-a4bc-4dd3-9a78-33ec38595a59')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-46f9888d-a4bc-4dd3-9a78-33ec38595a59 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#train test split using sklearn\n",
        "train3, eval3 = train_test_split(data3, test_size = split_size, random_state = 42)\n",
        "train3 = train3.reset_index(drop = True)\n",
        "eval3 = eval3.reset_index(drop = True)\n",
        "print(train3.shape)\n",
        "print(eval3.shape)\n",
        "train3.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "gpfh5DCXaBrA",
        "outputId": "55112cce-7f56-4efc-947a-3d41d4b67993"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(72717, 2)\n",
            "(8080, 2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             English  \\\n",
              "0  It is actually 1: (2 : (3 : [ ] ) ) and so thi...   \n",
              "1  The child can even go in the state of unconsci...   \n",
              "2  As far as this second channel concerns , natur...   \n",
              "3                      I did not smoke for 3 months.   \n",
              "4  Earlier in the open air food court at the exit...   \n",
              "\n",
              "                                               Hindi  \n",
              "0  यह वास्तव में 1: (2: (3: [])) है, और इसलिए इसक...  \n",
              "1  शिशु कछ वक्‍त के लिए बेहोशी की हालत में भी जा ...  \n",
              "2  जहाँ तक इस दूसरे चैनल का सवाल है , तो ’ मैट्रो...  \n",
              "3  धूम्रपान छोड़ना आसान है लेकिन धूम्रपान के प्रल...  \n",
              "4  पहले यहाँ मंडपों के निकास पर बने ओपन एयर फूड क...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d6343c27-e864-4cc5-a3ec-e2cd6a31f15d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English</th>\n",
              "      <th>Hindi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>It is actually 1: (2 : (3 : [ ] ) ) and so thi...</td>\n",
              "      <td>यह वास्तव में 1: (2: (3: [])) है, और इसलिए इसक...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The child can even go in the state of unconsci...</td>\n",
              "      <td>शिशु कछ वक्‍त के लिए बेहोशी की हालत में भी जा ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>As far as this second channel concerns , natur...</td>\n",
              "      <td>जहाँ तक इस दूसरे चैनल का सवाल है , तो ’ मैट्रो...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I did not smoke for 3 months.</td>\n",
              "      <td>धूम्रपान छोड़ना आसान है लेकिन धूम्रपान के प्रल...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Earlier in the open air food court at the exit...</td>\n",
              "      <td>पहले यहाँ मंडपों के निकास पर बने ओपन एयर फूड क...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d6343c27-e864-4cc5-a3ec-e2cd6a31f15d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d6343c27-e864-4cc5-a3ec-e2cd6a31f15d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d6343c27-e864-4cc5-a3ec-e2cd6a31f15d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a3f500fc-b8b1-473d-acad-9786e1ce1a2e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a3f500fc-b8b1-473d-acad-9786e1ce1a2e')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a3f500fc-b8b1-473d-acad-9786e1ce1a2e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#train test split using sklearn\n",
        "train4, eval4 = train_test_split(data4, test_size = split_size, random_state = 42)\n",
        "train4 = train4.reset_index(drop = True)\n",
        "eval4 = eval4.reset_index(drop = True)\n",
        "print(train4.shape)\n",
        "print(eval4.shape)\n",
        "train4.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "wp64Bs47aCqu",
        "outputId": "34bd12fe-0ea0-40f2-d9e9-9d1b967926d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(42114, 2)\n",
            "(4680, 2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             English  \\\n",
              "0  After the angst do they start haveing headache...   \n",
              "1  From the plants grown from the planted horizon...   \n",
              "2  Several 16th-century texts survive that offer ...   \n",
              "3  Under the Pallava dynasty, a unique form of Gr...   \n",
              "4  With each bottle there is also a spoon of 2 ml...   \n",
              "\n",
              "                                             Kannada  \n",
              "0  ಕೋಪದ ನಂತರ ಅವರಿಗೆ ತಲೆನೋವು ಅಥವ ಹೊಟ್ಟೆನೋವು ಆಗುತ್ತ...  \n",
              "1  ಐ.ಬಿ.ಎ. 50 ಪಿ.ಪಿ.ಎಮ್.ನಿಂದ ಉಪಚರಿಸಿದ ಕಲಮುಗಳಲ್ಲಿ ...  \n",
              "2  ರಾಣಿ ಪದ್ಮಿನಿಯ ಜೀವನದ ಬಗ್ಗೆ ವ್ಯತ್ಯಾಸದಿಂದ ಕೂಡಿದ ವ...  \n",
              "3  ಪಲ್ಲವ ರಾಜವಂಶದ ಅಡಿಯಲ್ಲಿ, ಬ್ರಾಹ್ಮೀ ಲಿಪಿಯ ಒಂದು ವಿ...  \n",
              "4  ಪ್ರತಿ ಶೀಸೆಯ ಜೊತೆ 2 ಮಿಲಿ ಅಳತೆಯ ಒಂದು ಚಮಚವು ಕೂಡ ಇ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7aa07ff6-c404-4318-a71c-f9789d5c7447\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English</th>\n",
              "      <th>Kannada</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>After the angst do they start haveing headache...</td>\n",
              "      <td>ಕೋಪದ ನಂತರ ಅವರಿಗೆ ತಲೆನೋವು ಅಥವ ಹೊಟ್ಟೆನೋವು ಆಗುತ್ತ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>From the plants grown from the planted horizon...</td>\n",
              "      <td>ಐ.ಬಿ.ಎ. 50 ಪಿ.ಪಿ.ಎಮ್.ನಿಂದ ಉಪಚರಿಸಿದ ಕಲಮುಗಳಲ್ಲಿ ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Several 16th-century texts survive that offer ...</td>\n",
              "      <td>ರಾಣಿ ಪದ್ಮಿನಿಯ ಜೀವನದ ಬಗ್ಗೆ ವ್ಯತ್ಯಾಸದಿಂದ ಕೂಡಿದ ವ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Under the Pallava dynasty, a unique form of Gr...</td>\n",
              "      <td>ಪಲ್ಲವ ರಾಜವಂಶದ ಅಡಿಯಲ್ಲಿ, ಬ್ರಾಹ್ಮೀ ಲಿಪಿಯ ಒಂದು ವಿ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>With each bottle there is also a spoon of 2 ml...</td>\n",
              "      <td>ಪ್ರತಿ ಶೀಸೆಯ ಜೊತೆ 2 ಮಿಲಿ ಅಳತೆಯ ಒಂದು ಚಮಚವು ಕೂಡ ಇ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7aa07ff6-c404-4318-a71c-f9789d5c7447')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7aa07ff6-c404-4318-a71c-f9789d5c7447 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7aa07ff6-c404-4318-a71c-f9789d5c7447');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b7b34e85-d716-453b-9a85-24472711f1f9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b7b34e85-d716-453b-9a85-24472711f1f9')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b7b34e85-d716-453b-9a85-24472711f1f9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#train test split using sklearn\n",
        "train5, eval5 = train_test_split(data5, test_size = split_size, random_state = 42)\n",
        "train5 = train5.reset_index(drop = True)\n",
        "eval5 = eval5.reset_index(drop = True)\n",
        "print(train5.shape)\n",
        "print(eval5.shape)\n",
        "train5.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "LI1TJTL0aDJ4",
        "outputId": "0daf689d-6f19-42eb-85fb-2175622e6157"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(48651, 2)\n",
            "(5406, 2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             English  \\\n",
              "0                     what's the weather in portland   \n",
              "1  Leaving deaf - dumb the assistants traveling w...   \n",
              "2                    follow trump campaign news feed   \n",
              "3  He talked about that radical change in the lif...   \n",
              "4                        how has your day been today   \n",
              "\n",
              "                                           Malayalam  \n",
              "0                  തിരുവനന്തപുരത്തെ കാലാവസ്ഥ എന്താണ്  \n",
              "1  ഇതുകൂടാതെ സീസണ്‍ ടിക്കറ്റില്‍ വികലാംഗര്‍ക്ക് 5...  \n",
              "2             ട്രംപ് പ്രചാരണ വാർത്താ ഫീഡ് പിന്തുടരുക  \n",
              "3  അദ്ദേഹം ലോകത്തിലെ ഓരോ വ്യക്തിയുടേയും ജീവിതത്തി...  \n",
              "4                   നിങ്ങളുടെ ഇന്ന് എങ്ങനെയായിരുന്നു  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c77fdae2-30b3-4e77-9421-cb8f9de1e693\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English</th>\n",
              "      <th>Malayalam</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>what's the weather in portland</td>\n",
              "      <td>തിരുവനന്തപുരത്തെ കാലാവസ്ഥ എന്താണ്</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Leaving deaf - dumb the assistants traveling w...</td>\n",
              "      <td>ഇതുകൂടാതെ സീസണ്‍ ടിക്കറ്റില്‍ വികലാംഗര്‍ക്ക് 5...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>follow trump campaign news feed</td>\n",
              "      <td>ട്രംപ് പ്രചാരണ വാർത്താ ഫീഡ് പിന്തുടരുക</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>He talked about that radical change in the lif...</td>\n",
              "      <td>അദ്ദേഹം ലോകത്തിലെ ഓരോ വ്യക്തിയുടേയും ജീവിതത്തി...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>how has your day been today</td>\n",
              "      <td>നിങ്ങളുടെ ഇന്ന് എങ്ങനെയായിരുന്നു</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c77fdae2-30b3-4e77-9421-cb8f9de1e693')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c77fdae2-30b3-4e77-9421-cb8f9de1e693 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c77fdae2-30b3-4e77-9421-cb8f9de1e693');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-eea46d67-0b8d-489a-a11c-652c8389cb1f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-eea46d67-0b8d-489a-a11c-652c8389cb1f')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-eea46d67-0b8d-489a-a11c-652c8389cb1f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#train test split using sklearn\n",
        "train6, eval6 = train_test_split(data6, test_size = split_size, random_state = 42)\n",
        "train6 = train6.reset_index(drop = True)\n",
        "eval6 = eval6.reset_index(drop = True)\n",
        "print(train6.shape)\n",
        "print(eval6.shape)\n",
        "train6.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "uSjgP_rWaDmL",
        "outputId": "cc451308-d576-4f68-f245-49c5587f54ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(52524, 2)\n",
            "(5837, 2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             English  \\\n",
              "0           The road is the only means of transport.   \n",
              "1  In the button hole surgery the patient faces m...   \n",
              "2  The more they sing, the more nuts and sweets t...   \n",
              "3  These youngsters are a part of a global campai...   \n",
              "4  resume the song from the audiobook by michael ...   \n",
              "\n",
              "                                               Tamil  \n",
              "0              சாலை வழி போக்குவரத்து மட்டுமே உள்ளது.  \n",
              "1  பட்டன்ஹோல்சர்ஜரியில் நோயாளிக்கு , அறுவைசிகிச்ச...  \n",
              "2  அவர்கள் எவ்வளவு அதிகமாக பாடுகிறார்களோ, அவ்வளவு...  \n",
              "3  2013ல் இந்த இளைஞர்கள் ஒரு உலகளாவிய இயக்கம் ஐஎஇ...  \n",
              "4  ஏ. ஆர். ரஹ்மான் ஆடியோ புத்தகத்திலிருந்து பாடலை...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f6e1c1eb-512c-4861-b542-85ab01d20d94\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English</th>\n",
              "      <th>Tamil</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The road is the only means of transport.</td>\n",
              "      <td>சாலை வழி போக்குவரத்து மட்டுமே உள்ளது.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>In the button hole surgery the patient faces m...</td>\n",
              "      <td>பட்டன்ஹோல்சர்ஜரியில் நோயாளிக்கு , அறுவைசிகிச்ச...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The more they sing, the more nuts and sweets t...</td>\n",
              "      <td>அவர்கள் எவ்வளவு அதிகமாக பாடுகிறார்களோ, அவ்வளவு...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>These youngsters are a part of a global campai...</td>\n",
              "      <td>2013ல் இந்த இளைஞர்கள் ஒரு உலகளாவிய இயக்கம் ஐஎஇ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>resume the song from the audiobook by michael ...</td>\n",
              "      <td>ஏ. ஆர். ரஹ்மான் ஆடியோ புத்தகத்திலிருந்து பாடலை...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f6e1c1eb-512c-4861-b542-85ab01d20d94')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f6e1c1eb-512c-4861-b542-85ab01d20d94 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f6e1c1eb-512c-4861-b542-85ab01d20d94');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ad693900-0aaf-462c-a0ec-3b83db1807ec\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ad693900-0aaf-462c-a0ec-3b83db1807ec')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ad693900-0aaf-462c-a0ec-3b83db1807ec button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#train test split using sklearn\n",
        "train7, eval7 = train_test_split(data7, test_size = split_size, random_state = 42)\n",
        "train7 = train7.reset_index(drop = True)\n",
        "eval7 = eval7.reset_index(drop = True)\n",
        "print(train7.shape)\n",
        "print(eval7.shape)\n",
        "train7.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "ChIIHnq_aEDA",
        "outputId": "28485289-2e34-472d-8097-7d4b7afe4bef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(40413, 2)\n",
            "(4491, 2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             English  \\\n",
              "0  The institutions that run special schools for ...   \n",
              "1        place an order for two pizzas from dominoes   \n",
              "2                    knowledge about food processing   \n",
              "3                Patient feels extreme nervousness .   \n",
              "4  When you stay accountable this way, you'll ten...   \n",
              "\n",
              "                                               Telgu  \n",
              "0  ఏ సంస్థలు అయితే విభిన్న రకాల వికలాంగులకు ప్రత్...  \n",
              "1    ఔరాస్ పిజ్జా నుంచి రెండు పిజ్జాస్ ఆర్డర్ పెట్టు  \n",
              "2                  ఫుడ్ ప్రాసెసింగ్ గురించి నాలెడ్జ్  \n",
              "3                రోగికి ఎక్కువగా కంగారు కలుగుతుంది .  \n",
              "4  మీరు ఈ విధంగా జవాబుదారీగా ఉన్నప్పుడు, మీరు కొం...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a17fba1a-9319-4a4f-be2a-133ea99dd2bf\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English</th>\n",
              "      <th>Telgu</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The institutions that run special schools for ...</td>\n",
              "      <td>ఏ సంస్థలు అయితే విభిన్న రకాల వికలాంగులకు ప్రత్...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>place an order for two pizzas from dominoes</td>\n",
              "      <td>ఔరాస్ పిజ్జా నుంచి రెండు పిజ్జాస్ ఆర్డర్ పెట్టు</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>knowledge about food processing</td>\n",
              "      <td>ఫుడ్ ప్రాసెసింగ్ గురించి నాలెడ్జ్</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Patient feels extreme nervousness .</td>\n",
              "      <td>రోగికి ఎక్కువగా కంగారు కలుగుతుంది .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>When you stay accountable this way, you'll ten...</td>\n",
              "      <td>మీరు ఈ విధంగా జవాబుదారీగా ఉన్నప్పుడు, మీరు కొం...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a17fba1a-9319-4a4f-be2a-133ea99dd2bf')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a17fba1a-9319-4a4f-be2a-133ea99dd2bf button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a17fba1a-9319-4a4f-be2a-133ea99dd2bf');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-94652890-b60d-4090-a794-0757cf219088\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-94652890-b60d-4090-a794-0757cf219088')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-94652890-b60d-4090-a794-0757cf219088 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UcUSb4mI3TRV"
      },
      "outputs": [],
      "source": [
        "#defining the iterable class for creating the iterable dataset\n",
        "#it takes two series as input namely hindi and english sentence series and\n",
        "#generates a tuple of source and target sentence as follows\n",
        "class MyIterableDataset(IterableDataset):\n",
        "    def __init__(self, english_sentences, hindi_sentences):\n",
        "        self.english_sentences = english_sentences\n",
        "        self.hindi_sentences = hindi_sentences\n",
        "        self.index = 0\n",
        "\n",
        "    def __iter__(self):\n",
        "        return self\n",
        "\n",
        "    def __next__(self):\n",
        "        if self.index >= len(self.english_sentences):\n",
        "            raise StopIteration\n",
        "        else:\n",
        "            english_sentence = self.english_sentences[self.index]\n",
        "            hindi_sentence = self.hindi_sentences[self.index]\n",
        "            self.index += 1\n",
        "            return hindi_sentence, english_sentence\n",
        "\n",
        "# Example usage\n",
        "# train_iter = MyIterableDataset(train['english'], train['hindi'])\n",
        "# eval_iter = MyIterableDataset(eval['english'], eval['hindi'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ciihdBj98qQ"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "# !python -m spacy download en_core_web_sm\n",
        "eng = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "from indicnlp.tokenize import indic_tokenize\n",
        "\n",
        "def engTokenize(text):\n",
        "    \"\"\"\n",
        "    Tokenize an English text and return a list of tokens\n",
        "    \"\"\"\n",
        "    return [str(token.text) for token in eng.tokenizer(str(text))]\n",
        "\n",
        "def hiTokenize(text):\n",
        "    \"\"\"\n",
        "    Tokenize a German text and return a list of tokens\n",
        "    \"\"\"\n",
        "    return [str(t) for t in indic_tokenize.trivial_tokenize(str(text))]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MyIterableEnglish(IterableDataset):\n",
        "    def __init__(self, english_sentences):\n",
        "        self.english_sentences = english_sentences\n",
        "        # self.hindi_sentences = hindi_sentences\n",
        "        self.index = 0\n",
        "\n",
        "    def __iter__(self):\n",
        "        return self\n",
        "\n",
        "    def __next__(self):\n",
        "        if self.index >= len(self.english_sentences):\n",
        "            raise StopIteration\n",
        "        else:\n",
        "            english_sentence = self.english_sentences[self.index]\n",
        "            # hindi_sentence = self.hindi_sentences[self.index]\n",
        "            self.index += 1\n",
        "            return english_sentence"
      ],
      "metadata": {
        "id": "L9zW3Zxnv4qo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.concat([train1[TGT_LANGUAGE], train2[TGT_LANGUAGE], train3[TGT_LANGUAGE],train4[TGT_LANGUAGE],train5[TGT_LANGUAGE],train6[TGT_LANGUAGE],train7[TGT_LANGUAGE]], ignore_index=True)\n"
      ],
      "metadata": {
        "id": "d7XtlqY3vwBU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cJ0QbyUg_Mfm"
      },
      "outputs": [],
      "source": [
        "# def getTokens(data_iter, place):\n",
        "#     \"\"\"\n",
        "#     Function to yield tokens from an iterator. Since, our iterator contains\n",
        "#     tuple of sentences (source and target), `place` parameters defines for which\n",
        "#     index to return the tokens for. `place=0` for source and `place=1` for target\n",
        "#     \"\"\"\n",
        "#     for english, german in data_iter:\n",
        "#         if place == 0:\n",
        "#             yield engTokenize(english)\n",
        "#         else:\n",
        "#             yield hiTokenize(german)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = {}\n",
        "#vocab_size[SRC_LANGUAGE1] = 30000\n",
        "vocab_size[TGT_LANGUAGE] = 70000\n",
        "\n",
        "# Place-holders\n",
        "token_transform = {}\n",
        "vocab_transform = {}\n",
        "\n",
        "\n",
        "token_transform[TGT_LANGUAGE] = engTokenize\n",
        "\n",
        "# function to generate the tokens for each language\n",
        "def yield_tokens(data_iter: Iterable) -> List[str]:\n",
        "    language_index = {TGT_LANGUAGE: 0}\n",
        "\n",
        "    for data_sample in data_iter:\n",
        "        yield token_transform[TGT_LANGUAGE](data_sample)\n",
        "\n",
        "# Define special symbols and indices\n",
        "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
        "special_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']\n",
        "\n",
        "for ln in [TGT_LANGUAGE]:\n",
        "    #create the iterator object of the dataset given\n",
        "    train_iter = MyIterableEnglish(train)\n",
        "    vocab_transform[ln] = build_vocab_from_iterator(yield_tokens(train_iter),\n",
        "                                                    min_freq=2,\n",
        "                                                    specials=special_symbols,\n",
        "                                                    special_first=True,\n",
        "                                                    max_tokens = vocab_size[ln]\n",
        "                                                    )\n",
        "\n",
        "#setting the default index to unknown index which means that it will assume the token to be unknown if\n",
        "#it sees a word not in the dictionary.\n",
        "for ln in [TGT_LANGUAGE]:\n",
        "  vocab_transform[ln].set_default_index(UNK_IDX)"
      ],
      "metadata": {
        "id": "tXq_UCjJuIwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_transform[TGT_LANGUAGE](token_transform[TGT_LANGUAGE]('Hello darkness my old friend'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onrAvaJJwpYu",
        "outputId": "784fbf9c-636b-4f6e-a2b4-99b5f4403c0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[11402, 7019, 62, 239, 1505]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J8au7liA0dul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WFJQouRvEwmb"
      },
      "outputs": [],
      "source": [
        "vocab_size1 = {}\n",
        "vocab_size1[SRC_LANGUAGE1] = 30000\n",
        "vocab_size1[TGT_LANGUAGE] = 30000\n",
        "\n",
        "# Place-holders\n",
        "token_transform1 = {}\n",
        "vocab_transform1 = {}\n",
        "\n",
        "token_transform1[SRC_LANGUAGE1] = hiTokenize\n",
        "token_transform1[TGT_LANGUAGE] = engTokenize\n",
        "\n",
        "# function to generate the tokens for each language\n",
        "def yield_tokens(data_iter: Iterable, language: str) -> List[str]:\n",
        "    language_index = {SRC_LANGUAGE1: 0, TGT_LANGUAGE: 1}\n",
        "\n",
        "    for data_sample in data_iter:\n",
        "        yield token_transform1[language](data_sample[language_index[language]])\n",
        "\n",
        "# Define special symbols and indices\n",
        "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
        "special_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']\n",
        "\n",
        "for ln in [SRC_LANGUAGE1, TGT_LANGUAGE]:\n",
        "    #create the iterator object of the dataset given\n",
        "    train_iter = MyIterableDataset(train1[TGT_LANGUAGE], train1[SRC_LANGUAGE1])\n",
        "    vocab_transform1[ln] = build_vocab_from_iterator(yield_tokens(train_iter, ln),\n",
        "                                                    min_freq=2,\n",
        "                                                    specials=special_symbols,\n",
        "                                                    special_first=True,\n",
        "                                                    max_tokens = vocab_size1[ln]\n",
        "                                                    )\n",
        "\n",
        "#setting the default index to unknown index which means that it will assume the token to be unknown if\n",
        "#it sees a word not in the dictionary.\n",
        "for ln in [SRC_LANGUAGE1, TGT_LANGUAGE]:\n",
        "  vocab_transform1[ln].set_default_index(UNK_IDX)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size2 = {}\n",
        "vocab_size2[SRC_LANGUAGE2] = 30000\n",
        "vocab_size2[TGT_LANGUAGE] = 30000\n",
        "\n",
        "# Place-holders\n",
        "token_transform2 = {}\n",
        "vocab_transform2 = {}\n",
        "\n",
        "token_transform2[SRC_LANGUAGE2] = hiTokenize\n",
        "token_transform2[TGT_LANGUAGE] = engTokenize\n",
        "\n",
        "# function to generate the tokens for each language\n",
        "def yield_tokens(data_iter: Iterable, language: str) -> List[str]:\n",
        "    language_index = {SRC_LANGUAGE2: 0, TGT_LANGUAGE: 1}\n",
        "\n",
        "    for data_sample in data_iter:\n",
        "        yield token_transform2[language](data_sample[language_index[language]])\n",
        "\n",
        "# Define special symbols and indices\n",
        "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
        "special_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']\n",
        "\n",
        "for ln in [SRC_LANGUAGE2, TGT_LANGUAGE]:\n",
        "    #create the iterator object of the dataset given\n",
        "    train_iter = MyIterableDataset(train2[TGT_LANGUAGE], train2[SRC_LANGUAGE2])\n",
        "    vocab_transform2[ln] = build_vocab_from_iterator(yield_tokens(train_iter, ln),\n",
        "                                                    min_freq=2,\n",
        "                                                    specials=special_symbols,\n",
        "                                                    special_first=True,\n",
        "                                                    max_tokens = vocab_size2[ln]\n",
        "                                                    )\n",
        "\n",
        "#setting the default index to unknown index which means that it will assume the token to be unknown if\n",
        "#it sees a word not in the dictionary.\n",
        "for ln in [SRC_LANGUAGE2, TGT_LANGUAGE]:\n",
        "  vocab_transform2[ln].set_default_index(UNK_IDX)"
      ],
      "metadata": {
        "id": "9PoPcIx5pDQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size2 = {}\n",
        "vocab_size2[SRC_LANGUAGE2] = 30000\n",
        "vocab_size2[TGT_LANGUAGE] = 30000\n",
        "\n",
        "# Place-holders\n",
        "token_transform2 = {}\n",
        "vocab_transform2 = {}\n",
        "\n",
        "token_transform2[SRC_LANGUAGE2] = hiTokenize\n",
        "token_transform2[TGT_LANGUAGE] = engTokenize\n",
        "\n",
        "# function to generate the tokens for each language\n",
        "def yield_tokens(data_iter: Iterable, language: str) -> List[str]:\n",
        "    language_index = {SRC_LANGUAGE2: 0, TGT_LANGUAGE: 1}\n",
        "\n",
        "    for data_sample in data_iter:\n",
        "        yield token_transform2[language](data_sample[language_index[language]])\n",
        "\n",
        "# Define special symbols and indices\n",
        "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
        "special_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']\n",
        "\n",
        "for ln in [SRC_LANGUAGE2, TGT_LANGUAGE]:\n",
        "    #create the iterator object of the dataset given\n",
        "    train_iter = MyIterableDataset(train2[TGT_LANGUAGE], train2[SRC_LANGUAGE2])\n",
        "    vocab_transform2[ln] = build_vocab_from_iterator(yield_tokens(train_iter, ln),\n",
        "                                                    min_freq=2,\n",
        "                                                    specials=special_symbols,\n",
        "                                                    special_first=True,\n",
        "                                                    max_tokens = vocab_size2[ln]\n",
        "                                                    )\n",
        "\n",
        "#setting the default index to unknown index which means that it will assume the token to be unknown if\n",
        "#it sees a word not in the dictionary.\n",
        "for ln in [SRC_LANGUAGE2, TGT_LANGUAGE]:\n",
        "  vocab_transform2[ln].set_default_index(UNK_IDX)"
      ],
      "metadata": {
        "id": "lHJ7HR4hb3At"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size3 = {}\n",
        "vocab_size3[SRC_LANGUAGE3] = 30000\n",
        "vocab_size3[TGT_LANGUAGE] = 30000\n",
        "\n",
        "# Place-holders\n",
        "token_transform3 = {}\n",
        "vocab_transform3 = {}\n",
        "\n",
        "token_transform3[SRC_LANGUAGE3] = hiTokenize\n",
        "token_transform3[TGT_LANGUAGE] = engTokenize\n",
        "\n",
        "# function to generate the tokens for each language\n",
        "def yield_tokens(data_iter: Iterable, language: str) -> List[str]:\n",
        "    language_index = {SRC_LANGUAGE3: 0, TGT_LANGUAGE: 1}\n",
        "\n",
        "    for data_sample in data_iter:\n",
        "        yield token_transform3[language](data_sample[language_index[language]])\n",
        "\n",
        "# Define special symbols and indices\n",
        "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
        "special_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']\n",
        "\n",
        "for ln in [SRC_LANGUAGE3, TGT_LANGUAGE]:\n",
        "    #create the iterator object of the dataset given\n",
        "    train_iter = MyIterableDataset(train3[TGT_LANGUAGE], train3[SRC_LANGUAGE3])\n",
        "    vocab_transform3[ln] = build_vocab_from_iterator(yield_tokens(train_iter, ln),\n",
        "                                                    min_freq=2,\n",
        "                                                    specials=special_symbols,\n",
        "                                                    special_first=True,\n",
        "                                                    max_tokens = vocab_size3[ln]\n",
        "                                                    )\n",
        "\n",
        "#setting the default index to unknown index which means that it will assume the token to be unknown if\n",
        "#it sees a word not in the dictionary.\n",
        "for ln in [SRC_LANGUAGE3, TGT_LANGUAGE]:\n",
        "  vocab_transform3[ln].set_default_index(UNK_IDX)"
      ],
      "metadata": {
        "id": "DdgdXzd7cvX5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size4 = {}\n",
        "vocab_size4[SRC_LANGUAGE4] = 30000\n",
        "vocab_size4[TGT_LANGUAGE] = 30000\n",
        "\n",
        "# Place-holders\n",
        "token_transform4 = {}\n",
        "vocab_transform4 = {}\n",
        "\n",
        "token_transform4[SRC_LANGUAGE4] = hiTokenize\n",
        "token_transform4[TGT_LANGUAGE] = engTokenize\n",
        "\n",
        "# function to generate the tokens for each language\n",
        "def yield_tokens(data_iter: Iterable, language: str) -> List[str]:\n",
        "    language_index = {SRC_LANGUAGE4: 0, TGT_LANGUAGE: 1}\n",
        "\n",
        "    for data_sample in data_iter:\n",
        "        yield token_transform4[language](data_sample[language_index[language]])\n",
        "\n",
        "# Define special symbols and indices\n",
        "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
        "special_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']\n",
        "\n",
        "for ln in [SRC_LANGUAGE4, TGT_LANGUAGE]:\n",
        "    #create the iterator object of the dataset given\n",
        "    train_iter = MyIterableDataset(train4[TGT_LANGUAGE], train4[SRC_LANGUAGE4])\n",
        "    vocab_transform4[ln] = build_vocab_from_iterator(yield_tokens(train_iter, ln),\n",
        "                                                    min_freq=2,\n",
        "                                                    specials=special_symbols,\n",
        "                                                    special_first=True,\n",
        "                                                    max_tokens = vocab_size4[ln]\n",
        "                                                    )\n",
        "\n",
        "#setting the default index to unknown index which means that it will assume the token to be unknown if\n",
        "#it sees a word not in the dictionary.\n",
        "for ln in [SRC_LANGUAGE4, TGT_LANGUAGE]:\n",
        "  vocab_transform4[ln].set_default_index(UNK_IDX)"
      ],
      "metadata": {
        "id": "mLZUNJcOdF_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size5 = {}\n",
        "vocab_size5[SRC_LANGUAGE5] = 30000\n",
        "vocab_size5[TGT_LANGUAGE] = 30000\n",
        "\n",
        "# Place-holders\n",
        "token_transform5 = {}\n",
        "vocab_transform5 = {}\n",
        "\n",
        "token_transform5[SRC_LANGUAGE5] = hiTokenize\n",
        "token_transform5[TGT_LANGUAGE] = engTokenize\n",
        "\n",
        "# function to generate the tokens for each language\n",
        "def yield_tokens(data_iter: Iterable, language: str) -> List[str]:\n",
        "    language_index = {SRC_LANGUAGE5: 0, TGT_LANGUAGE: 1}\n",
        "\n",
        "    for data_sample in data_iter:\n",
        "        yield token_transform5[language](data_sample[language_index[language]])\n",
        "\n",
        "# Define special symbols and indices\n",
        "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
        "special_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']\n",
        "\n",
        "for ln in [SRC_LANGUAGE5, TGT_LANGUAGE]:\n",
        "    #create the iterator object of the dataset given\n",
        "    train_iter = MyIterableDataset(train5[TGT_LANGUAGE], train5[SRC_LANGUAGE5])\n",
        "    vocab_transform5[ln] = build_vocab_from_iterator(yield_tokens(train_iter, ln),\n",
        "                                                    min_freq=2,\n",
        "                                                    specials=special_symbols,\n",
        "                                                    special_first=True,\n",
        "                                                    max_tokens = vocab_size5[ln]\n",
        "                                                    )\n",
        "\n",
        "#setting the default index to unknown index which means that it will assume the token to be unknown if\n",
        "#it sees a word not in the dictionary.\n",
        "for ln in [SRC_LANGUAGE5, TGT_LANGUAGE]:\n",
        "  vocab_transform5[ln].set_default_index(UNK_IDX)"
      ],
      "metadata": {
        "id": "e-eihfYzdG3_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size6 = {}\n",
        "vocab_size6[SRC_LANGUAGE6] = 30000\n",
        "vocab_size6[TGT_LANGUAGE] = 30000\n",
        "\n",
        "# Place-holders\n",
        "token_transform6 = {}\n",
        "vocab_transform6 = {}\n",
        "\n",
        "token_transform6[SRC_LANGUAGE6] = hiTokenize\n",
        "token_transform6[TGT_LANGUAGE] = engTokenize\n",
        "\n",
        "# function to generate the tokens for each language\n",
        "def yield_tokens(data_iter: Iterable, language: str) -> List[str]:\n",
        "    language_index = {SRC_LANGUAGE6: 0, TGT_LANGUAGE: 1}\n",
        "\n",
        "    for data_sample in data_iter:\n",
        "        yield token_transform6[language](data_sample[language_index[language]])\n",
        "\n",
        "# Define special symbols and indices\n",
        "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
        "special_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']\n",
        "\n",
        "for ln in [SRC_LANGUAGE6, TGT_LANGUAGE]:\n",
        "    #create the iterator object of the dataset given\n",
        "    train_iter = MyIterableDataset(train6[TGT_LANGUAGE], train6[SRC_LANGUAGE6])\n",
        "    vocab_transform6[ln] = build_vocab_from_iterator(yield_tokens(train_iter, ln),\n",
        "                                                    min_freq=2,\n",
        "                                                    specials=special_symbols,\n",
        "                                                    special_first=True,\n",
        "                                                    max_tokens = vocab_size6[ln]\n",
        "                                                    )\n",
        "\n",
        "#setting the default index to unknown index which means that it will assume the token to be unknown if\n",
        "#it sees a word not in the dictionary.\n",
        "for ln in [SRC_LANGUAGE6, TGT_LANGUAGE]:\n",
        "  vocab_transform6[ln].set_default_index(UNK_IDX)"
      ],
      "metadata": {
        "id": "JmXD-v7pdjhi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size7 = {}\n",
        "vocab_size7[SRC_LANGUAGE7] = 30000\n",
        "vocab_size7[TGT_LANGUAGE] = 30000\n",
        "\n",
        "# Place-holders\n",
        "token_transform7 = {}\n",
        "vocab_transform7 = {}\n",
        "\n",
        "token_transform7[SRC_LANGUAGE7] = hiTokenize\n",
        "token_transform7[TGT_LANGUAGE] = engTokenize\n",
        "\n",
        "# function to generate the tokens for each language\n",
        "def yield_tokens(data_iter: Iterable, language: str) -> List[str]:\n",
        "    language_index = {SRC_LANGUAGE7: 0, TGT_LANGUAGE: 1}\n",
        "\n",
        "    for data_sample in data_iter:\n",
        "        yield token_transform7[language](data_sample[language_index[language]])\n",
        "\n",
        "# Define special symbols and indices\n",
        "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
        "special_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']\n",
        "\n",
        "for ln in [SRC_LANGUAGE7, TGT_LANGUAGE]:\n",
        "    #create the iterator object of the dataset given\n",
        "    train_iter = MyIterableDataset(train7[TGT_LANGUAGE], train7[SRC_LANGUAGE7])\n",
        "    vocab_transform7[ln] = build_vocab_from_iterator(yield_tokens(train_iter, ln),\n",
        "                                                    min_freq=2,\n",
        "                                                    specials=special_symbols,\n",
        "                                                    special_first=True,\n",
        "                                                    max_tokens = vocab_size7[ln]\n",
        "                                                    )\n",
        "\n",
        "#setting the default index to unknown index which means that it will assume the token to be unknown if\n",
        "#it sees a word not in the dictionary.\n",
        "for ln in [SRC_LANGUAGE7, TGT_LANGUAGE]:\n",
        "  vocab_transform7[ln].set_default_index(UNK_IDX)"
      ],
      "metadata": {
        "id": "zB1w4BXYdkL_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_transform1[TGT_LANGUAGE] = vocab_transform[TGT_LANGUAGE]\n",
        "vocab_transform2[TGT_LANGUAGE] = vocab_transform[TGT_LANGUAGE]\n",
        "vocab_transform3[TGT_LANGUAGE]= vocab_transform[TGT_LANGUAGE]\n",
        "vocab_transform4[TGT_LANGUAGE]= vocab_transform[TGT_LANGUAGE]\n",
        "vocab_transform5[TGT_LANGUAGE]= vocab_transform[TGT_LANGUAGE]\n",
        "vocab_transform6[TGT_LANGUAGE]= vocab_transform[TGT_LANGUAGE]\n",
        "vocab_transform7[TGT_LANGUAGE]= vocab_transform[TGT_LANGUAGE]"
      ],
      "metadata": {
        "id": "qdohb0lj1MTP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token_transform1[TGT_LANGUAGE] = token_transform[TGT_LANGUAGE]\n",
        "token_transform2[TGT_LANGUAGE] = token_transform[TGT_LANGUAGE]\n",
        "token_transform3[TGT_LANGUAGE] = token_transform[TGT_LANGUAGE]\n",
        "token_transform4[TGT_LANGUAGE] = token_transform[TGT_LANGUAGE]\n",
        "token_transform5[TGT_LANGUAGE] = token_transform[TGT_LANGUAGE]\n",
        "token_transform6[TGT_LANGUAGE] = token_transform[TGT_LANGUAGE]\n",
        "token_transform7[TGT_LANGUAGE] = token_transform[TGT_LANGUAGE]\n"
      ],
      "metadata": {
        "id": "0nfoE4o21uC5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_transform7[TGT_LANGUAGE](token_transform7[TGT_LANGUAGE]('Hello darkness my old friend'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7F-aC6JD0xrw",
        "outputId": "c404fa42-2d52-42bf-f2be-4be5a754caa3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[11402, 7019, 62, 239, 1505]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_transform6[TGT_LANGUAGE](token_transform6[TGT_LANGUAGE]('Hello darkness my old friend'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yxcuFNsB08r3",
        "outputId": "59b4a09e-2d1f-476f-ca9e-9876aabd9e28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[11402, 7019, 62, 239, 1505]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_transform5[TGT_LANGUAGE](token_transform5[TGT_LANGUAGE]('Hello darkness my old friend'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8SEmkTlu0_QV",
        "outputId": "88d9bc70-f819-4185-bdd9-0fd73b30a37a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[11402, 7019, 62, 239, 1505]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "taLWE2OLaCJJ"
      },
      "outputs": [],
      "source": [
        "# helper Module that adds positional encoding to the token embedding to introduce a notion of word order.\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self,\n",
        "                 emb_size: int,\n",
        "                 dropout: float,\n",
        "                 maxlen: int = 7000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        den = torch.exp(- torch.arange(0, emb_size, 2)* math.log(10000) / emb_size)\n",
        "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
        "        pos_embedding = torch.zeros((maxlen, emb_size))\n",
        "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
        "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
        "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.register_buffer('pos_embedding', pos_embedding)\n",
        "\n",
        "    def forward(self, token_embedding: Tensor):\n",
        "        return self.dropout(token_embedding + self.pos_embedding[:token_embedding.size(0), :])\n",
        "\n",
        "# helper Module to convert tensor of input indices into corresponding tensor of token embeddings\n",
        "class TokenEmbedding(nn.Module):\n",
        "    def __init__(self, vocab_size: int, emb_size):\n",
        "        super(TokenEmbedding, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
        "        self.emb_size = emb_size\n",
        "\n",
        "    def forward(self, tokens: Tensor):\n",
        "        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)\n",
        "\n",
        "# The Network\n",
        "class Seq2SeqTransformer(nn.Module):\n",
        "    def __init__(self,\n",
        "                 num_encoder_layers: int,\n",
        "                 num_decoder_layers: int,\n",
        "                 emb_size: int,\n",
        "                 nhead: int,\n",
        "                 src_vocab_size: int,\n",
        "                 tgt_vocab_size: int,\n",
        "                 dim_feedforward: int = 512,\n",
        "                 dropout: float = 0.1):\n",
        "        super(Seq2SeqTransformer, self).__init__()\n",
        "        self.transformer = Transformer(d_model=emb_size,\n",
        "                                       nhead=nhead,\n",
        "                                       num_encoder_layers=num_encoder_layers,\n",
        "                                       num_decoder_layers=num_decoder_layers,\n",
        "                                       dim_feedforward=dim_feedforward,\n",
        "                                       dropout=dropout)\n",
        "        self.encoder1 = TransformerEncoder(TransformerEncoderLayer(d_model=emb_size, nhead=nhead),num_layers = num_encoder_layers)\n",
        "        self.encoder2 = TransformerEncoder(TransformerEncoderLayer(d_model=emb_size, nhead=nhead),num_layers = num_encoder_layers)\n",
        "        self.encoder3 = TransformerEncoder(TransformerEncoderLayer(d_model=emb_size, nhead=nhead),num_layers = num_encoder_layers)\n",
        "        self.encoder4 = TransformerEncoder(TransformerEncoderLayer(d_model=emb_size, nhead=nhead),num_layers = num_encoder_layers)\n",
        "        self.encoder5 = TransformerEncoder(TransformerEncoderLayer(d_model=emb_size, nhead=nhead),num_layers = num_encoder_layers)\n",
        "        self.encoder6 = TransformerEncoder(TransformerEncoderLayer(d_model=emb_size, nhead=nhead),num_layers = num_encoder_layers)\n",
        "        self.encoder7 = TransformerEncoder(TransformerEncoderLayer(d_model=emb_size, nhead=nhead),num_layers = num_encoder_layers)\n",
        "\n",
        "        self.decoder = TransformerDecoder(TransformerDecoderLayer(d_model=emb_size, nhead=nhead),num_layers = num_decoder_layers)\n",
        "\n",
        "        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n",
        "        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n",
        "        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n",
        "        self.positional_encoding = PositionalEncoding(\n",
        "            emb_size, dropout=dropout)\n",
        "\n",
        "    def forward(self,\n",
        "                src: Tensor,\n",
        "                trg: Tensor,\n",
        "                src_mask: Tensor,\n",
        "                tgt_mask: Tensor,\n",
        "                src_padding_mask: Tensor,\n",
        "                tgt_padding_mask: Tensor,\n",
        "                memory_key_padding_mask: Tensor,\n",
        "                Lang: str):\n",
        "        src_emb = self.positional_encoding(self.src_tok_emb(src))\n",
        "        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n",
        "        if Lang == 'Bengali':\n",
        "          mem = self.encoder1(src_emb, mask=src_mask, src_key_padding_mask = src_padding_mask)\n",
        "\n",
        "        elif Lang == 'Gujarati':\n",
        "          mem = self.encoder2(src_emb, mask=src_mask, src_key_padding_mask = src_padding_mask)\n",
        "\n",
        "        elif Lang == 'Hindi':\n",
        "          mem = self.encoder3(src_emb, mask=src_mask, src_key_padding_mask = src_padding_mask)\n",
        "\n",
        "        elif Lang == 'Kannada':\n",
        "          mem = self.encoder4(src_emb, mask=src_mask, src_key_padding_mask = src_padding_mask)\n",
        "\n",
        "        elif Lang == 'Malayalam':\n",
        "          mem = self.encoder5(src_emb, mask=src_mask, src_key_padding_mask = src_padding_mask)\n",
        "\n",
        "        elif Lang == 'Tamil':\n",
        "          mem = self.encoder6(src_emb, mask=src_mask, src_key_padding_mask = src_padding_mask)\n",
        "\n",
        "        elif Lang == 'Telgu':\n",
        "          mem = self.encoder7(src_emb, mask=src_mask, src_key_padding_mask = src_padding_mask)\n",
        "\n",
        "        outs = self.decoder(tgt_emb,mem, tgt_mask, None, tgt_key_padding_mask = tgt_padding_mask, memory_key_padding_mask = memory_key_padding_mask)\n",
        "        return self.generator(outs)\n",
        "\n",
        "    def encode(self, src: Tensor, src_mask: Tensor, Lang: str):\n",
        "        if Lang == 'Bengali':\n",
        "          return self.encoder1(self.positional_encoding(\n",
        "                            self.src_tok_emb(src)), src_mask)\n",
        "\n",
        "        elif Lang == 'Gujarati':\n",
        "          return self.encoder2(self.positional_encoding(\n",
        "                            self.src_tok_emb(src)), src_mask)\n",
        "        elif Lang == 'Hindi':\n",
        "          return self.encoder3(self.positional_encoding(\n",
        "                          self.src_tok_emb(src)), src_mask)\n",
        "        elif Lang == 'Kannada':\n",
        "          return self.encoder4(self.positional_encoding(\n",
        "                          self.src_tok_emb(src)), src_mask)\n",
        "        elif Lang == 'Malayalam':\n",
        "          return self.encoder5(self.positional_encoding(\n",
        "                          self.src_tok_emb(src)), src_mask)\n",
        "        elif Lang == 'Tamil':\n",
        "          return self.encoder6(self.positional_encoding(\n",
        "                          self.src_tok_emb(src)), src_mask)\n",
        "        elif Lang == 'Telgu':\n",
        "          return self.encoder7(self.positional_encoding(\n",
        "                          self.src_tok_emb(src)), src_mask)\n",
        "\n",
        "\n",
        "    def decode(self, tgt: Tensor, memory: Tensor, tgt_mask: Tensor):\n",
        "        return self.decoder(self.positional_encoding(\n",
        "                          self.tgt_tok_emb(tgt)), memory,\n",
        "                          tgt_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4SbdK3S-aCJP"
      },
      "outputs": [],
      "source": [
        "def generate_square_subsequent_mask(sz):\n",
        "    mask = (torch.triu(torch.ones((sz, sz), device=DEVICE)) == 1).transpose(0, 1)\n",
        "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "    return mask\n",
        "\n",
        "\n",
        "#mask creation for preventing the knowledge of presence of elements in future time steps\n",
        "def create_mask(src, tgt):\n",
        "    src_seq_len = src.shape[0]\n",
        "    tgt_seq_len = tgt.shape[0]\n",
        "\n",
        "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
        "    src_mask = torch.zeros((src_seq_len, src_seq_len),device=DEVICE).type(torch.bool)\n",
        "\n",
        "    src_padding_mask = (src == PAD_IDX).transpose(0, 1)\n",
        "    tgt_padding_mask = (tgt == PAD_IDX).transpose(0, 1)\n",
        "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dR-tgFmjaCJS",
        "outputId": "0e5ab5c2-4b29-4951-edac-7725a0415994"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30000\n",
            "70000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        }
      ],
      "source": [
        "#hyper-paramerter setting\n",
        "\n",
        "torch.manual_seed(0)\n",
        "\n",
        "SRC_VOCAB_SIZE = len(vocab_transform1[SRC_LANGUAGE1])\n",
        "TGT_VOCAB_SIZE = len(vocab_transform1[TGT_LANGUAGE])\n",
        "print(SRC_VOCAB_SIZE)\n",
        "print(TGT_VOCAB_SIZE)\n",
        "\n",
        "\n",
        "\n",
        "#creating the model with the hyperparams specified as above\n",
        "transformer = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE,\n",
        "                                 NHEAD, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE, FFN_HID_DIM)\n",
        "\n",
        "# initializes the weight matrices of the transformer model using Xavier uniform initialization\n",
        "for p in transformer.parameters():\n",
        "    if p.dim() > 1:\n",
        "        nn.init.xavier_uniform_(p)\n",
        "\n",
        "transformer = transformer.to(DEVICE) #push the model to the device\n",
        "\n",
        "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX) #cross entropy loss\n",
        "\n",
        "optimizer = torch.optim.Adam(transformer.parameters(), lr=lr, betas=betas, eps=eps) #adam optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N2Ter7p3aCJV"
      },
      "outputs": [],
      "source": [
        "'''creating the collate function to be passed in the dataloader which will basically apply\n",
        "this function to every entry of the batch and make the data feedable to the model\n",
        "'''\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "# helper function to club together sequential operations\n",
        "def sequential_transforms(*transforms):\n",
        "    def func(txt_input):\n",
        "        for transform in transforms:\n",
        "            txt_input = transform(txt_input)\n",
        "        return txt_input\n",
        "    return func\n",
        "\n",
        "# function to add BOS/EOS and create tensor for input sequence indices\n",
        "def tensor_transform(token_ids: List[int]):\n",
        "    return torch.cat((torch.tensor([BOS_IDX]),\n",
        "                      torch.tensor(token_ids),\n",
        "                      torch.tensor([EOS_IDX])))\n",
        "\n",
        "# src and tgt language text transforms to convert raw strings into tensors indices\n",
        "text_transform1 = {}\n",
        "for ln in [SRC_LANGUAGE1, TGT_LANGUAGE]:\n",
        "    text_transform1[ln] = sequential_transforms(token_transform1[ln], #Tokenization\n",
        "                                               vocab_transform1[ln], #Numericalization\n",
        "                                               tensor_transform) # Add BOS/EOS and create tensor\n",
        "\n",
        "\n",
        "# function to collate data samples into batch tensors\n",
        "def collate_fn1(batch):\n",
        "    src_batch, tgt_batch = [], []\n",
        "    for src_sample, tgt_sample in batch:\n",
        "        src_batch.append(text_transform1[SRC_LANGUAGE1](src_sample.rstrip(\"\\n\")))\n",
        "        tgt_batch.append(text_transform1[TGT_LANGUAGE](tgt_sample.rstrip(\"\\n\")))\n",
        "\n",
        "    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX)\n",
        "    tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX)\n",
        "    return src_batch, tgt_batch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# src and tgt language text transforms to convert raw strings into tensors indices\n",
        "text_transform2 = {}\n",
        "for ln in [SRC_LANGUAGE2, TGT_LANGUAGE]:\n",
        "    text_transform2[ln] = sequential_transforms(token_transform2[ln], #Tokenization\n",
        "                                               vocab_transform2[ln], #Numericalization\n",
        "                                               tensor_transform) # Add BOS/EOS and create tensor\n",
        "\n",
        "\n",
        "# function to collate data samples into batch tensors\n",
        "def collate_fn2(batch):\n",
        "    src_batch, tgt_batch = [], []\n",
        "    for src_sample, tgt_sample in batch:\n",
        "        src_batch.append(text_transform2[SRC_LANGUAGE2](src_sample.rstrip(\"\\n\")))\n",
        "        tgt_batch.append(text_transform2[TGT_LANGUAGE](tgt_sample.rstrip(\"\\n\")))\n",
        "\n",
        "    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX)\n",
        "    tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX)\n",
        "    return src_batch, tgt_batch"
      ],
      "metadata": {
        "id": "_nssERcSzxEy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# src and tgt language text transforms to convert raw strings into tensors indices\n",
        "text_transform3 = {}\n",
        "for ln in [SRC_LANGUAGE3, TGT_LANGUAGE]:\n",
        "    text_transform3[ln] = sequential_transforms(token_transform3[ln], #Tokenization\n",
        "                                               vocab_transform3[ln], #Numericalization\n",
        "                                               tensor_transform) # Add BOS/EOS and create tensor\n",
        "\n",
        "\n",
        "# function to collate data samples into batch tensors\n",
        "def collate_fn3(batch):\n",
        "    src_batch, tgt_batch = [], []\n",
        "    for src_sample, tgt_sample in batch:\n",
        "        src_batch.append(text_transform3[SRC_LANGUAGE3](src_sample.rstrip(\"\\n\")))\n",
        "        tgt_batch.append(text_transform3[TGT_LANGUAGE](tgt_sample.rstrip(\"\\n\")))\n",
        "\n",
        "    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX)\n",
        "    tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX)\n",
        "    return src_batch, tgt_batch"
      ],
      "metadata": {
        "id": "ltN5bqDSxVA3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# src and tgt language text transforms to convert raw strings into tensors indices\n",
        "text_transform4 = {}\n",
        "for ln in [SRC_LANGUAGE4, TGT_LANGUAGE]:\n",
        "    text_transform4[ln] = sequential_transforms(token_transform4[ln], #Tokenization\n",
        "                                               vocab_transform4[ln], #Numericalization\n",
        "                                               tensor_transform) # Add BOS/EOS and create tensor\n",
        "\n",
        "\n",
        "# function to collate data samples into batch tensors\n",
        "def collate_fn4(batch):\n",
        "    src_batch, tgt_batch = [], []\n",
        "    for src_sample, tgt_sample in batch:\n",
        "        src_batch.append(text_transform4[SRC_LANGUAGE4](src_sample.rstrip(\"\\n\")))\n",
        "        tgt_batch.append(text_transform4[TGT_LANGUAGE](tgt_sample.rstrip(\"\\n\")))\n",
        "\n",
        "    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX)\n",
        "    tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX)\n",
        "    return src_batch, tgt_batch"
      ],
      "metadata": {
        "id": "r_MIpOtAxYjm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# src and tgt language text transforms to convert raw strings into tensors indices\n",
        "text_transform5 = {}\n",
        "for ln in [SRC_LANGUAGE5, TGT_LANGUAGE]:\n",
        "    text_transform5[ln] = sequential_transforms(token_transform5[ln], #Tokenization\n",
        "                                               vocab_transform5[ln], #Numericalization\n",
        "                                               tensor_transform) # Add BOS/EOS and create tensor\n",
        "\n",
        "\n",
        "# function to collate data samples into batch tensors\n",
        "def collate_fn5(batch):\n",
        "    src_batch, tgt_batch = [], []\n",
        "    for src_sample, tgt_sample in batch:\n",
        "        src_batch.append(text_transform5[SRC_LANGUAGE5](src_sample.rstrip(\"\\n\")))\n",
        "        tgt_batch.append(text_transform5[TGT_LANGUAGE](tgt_sample.rstrip(\"\\n\")))\n",
        "\n",
        "    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX)\n",
        "    tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX)\n",
        "    return src_batch, tgt_batch"
      ],
      "metadata": {
        "id": "YhkwcBdpxbQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# src and tgt language text transforms to convert raw strings into tensors indices\n",
        "text_transform6 = {}\n",
        "for ln in [SRC_LANGUAGE6, TGT_LANGUAGE]:\n",
        "    text_transform6[ln] = sequential_transforms(token_transform6[ln], #Tokenization\n",
        "                                               vocab_transform6[ln], #Numericalization\n",
        "                                               tensor_transform) # Add BOS/EOS and create tensor\n",
        "\n",
        "\n",
        "# function to collate data samples into batch tensors\n",
        "def collate_fn6(batch):\n",
        "    src_batch, tgt_batch = [], []\n",
        "    for src_sample, tgt_sample in batch:\n",
        "        src_batch.append(text_transform6[SRC_LANGUAGE6](src_sample.rstrip(\"\\n\")))\n",
        "        tgt_batch.append(text_transform6[TGT_LANGUAGE](tgt_sample.rstrip(\"\\n\")))\n",
        "\n",
        "    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX)\n",
        "    tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX)\n",
        "    return src_batch, tgt_batch"
      ],
      "metadata": {
        "id": "kyAJu1R5xe66"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# src and tgt language text transforms to convert raw strings into tensors indices\n",
        "text_transform7 = {}\n",
        "for ln in [SRC_LANGUAGE7, TGT_LANGUAGE]:\n",
        "    text_transform7[ln] = sequential_transforms(token_transform7[ln], #Tokenization\n",
        "                                               vocab_transform7[ln], #Numericalization\n",
        "                                               tensor_transform) # Add BOS/EOS and create tensor\n",
        "\n",
        "\n",
        "# function to collate data samples into batch tensors\n",
        "def collate_fn7(batch):\n",
        "    src_batch, tgt_batch = [], []\n",
        "    for src_sample, tgt_sample in batch:\n",
        "        src_batch.append(text_transform7[SRC_LANGUAGE7](src_sample.rstrip(\"\\n\")))\n",
        "        tgt_batch.append(text_transform7[TGT_LANGUAGE](tgt_sample.rstrip(\"\\n\")))\n",
        "\n",
        "    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX)\n",
        "    tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX)\n",
        "    return src_batch, tgt_batch"
      ],
      "metadata": {
        "id": "Q_mOJ0LSxh5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6p-mjV1I3ZLm"
      },
      "outputs": [],
      "source": [
        "# train_iter = MyIterableDataset(train['english'], train['hindi'])\n",
        "# train_dataloader = DataLoader(train_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
        "# count = 1\n",
        "# for src, tgt in train_dataloader:\n",
        "#   if count == 5:\n",
        "#     break\n",
        "#   print(src.shape)\n",
        "#   count+=1\n",
        "\n",
        "#checking the shapes of different batches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vJxQj2U1IOWo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4qutjpTXIkEf",
        "outputId": "5a27a1a4-15ab-4f76-9f0e-d32655302d68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "61963\n",
            "6885\n",
            "number of train1 batches  3873\n",
            "number of eval1 batches  431\n",
            "42733\n",
            "4749\n",
            "number of train batches  2671\n",
            "number of eval batches  297\n",
            "72717\n",
            "8080\n",
            "number of train batches  4545\n",
            "number of eval batches  505\n",
            "42114\n",
            "4680\n",
            "number of train batches  2633\n",
            "number of eval batches  293\n",
            "48651\n",
            "5406\n",
            "number of train batches  3041\n",
            "number of eval batches  338\n",
            "52524\n",
            "5837\n",
            "number of train batches  3283\n",
            "number of eval batches  365\n",
            "40413\n",
            "4491\n",
            "number of train batches  2526\n",
            "number of eval batches  281\n"
          ]
        }
      ],
      "source": [
        "ntrain1 = train1.shape[0]\n",
        "neval1 = eval1.shape[0]\n",
        "print(ntrain1)\n",
        "print(neval1)\n",
        "\n",
        "#total number of samples in the train and eval dataset\n",
        "\n",
        "ntrainbatches1 = int(np.ceil(ntrain1/BATCH_SIZE))\n",
        "nevalbatches1 = int(np.ceil(neval1/BATCH_SIZE))\n",
        "print(\"number of train1 batches \", ntrainbatches1)\n",
        "print(\"number of eval1 batches \", nevalbatches1)\n",
        "\n",
        "#total number of batches in the train and eval dataset\n",
        "\n",
        "ntrain2 = train2.shape[0]\n",
        "neval2 = eval2.shape[0]\n",
        "print(ntrain2)\n",
        "print(neval2)\n",
        "\n",
        "#total number of samples in the train and eval dataset\n",
        "\n",
        "ntrainbatches2 = int(np.ceil(ntrain2/BATCH_SIZE))\n",
        "nevalbatches2 = int(np.ceil(neval2/BATCH_SIZE))\n",
        "print(\"number of train batches \", ntrainbatches2)\n",
        "print(\"number of eval batches \", nevalbatches2)\n",
        "\n",
        "#total number of batches in the train and eval dataset\n",
        "\n",
        "ntrain3 = train3.shape[0]\n",
        "neval3 = eval3.shape[0]\n",
        "print(ntrain3)\n",
        "print(neval3)\n",
        "\n",
        "#total number of samples in the train and eval dataset\n",
        "\n",
        "ntrainbatches3 = int(np.ceil(ntrain3/BATCH_SIZE))\n",
        "nevalbatches3 = int(np.ceil(neval3/BATCH_SIZE))\n",
        "print(\"number of train batches \", ntrainbatches3)\n",
        "print(\"number of eval batches \", nevalbatches3)\n",
        "\n",
        "#total number of batches in the train and eval dataset\n",
        "\n",
        "ntrain4 = train4.shape[0]\n",
        "neval4 = eval4.shape[0]\n",
        "print(ntrain4)\n",
        "print(neval4)\n",
        "\n",
        "#total number of samples in the train and eval dataset\n",
        "\n",
        "ntrainbatches4 = int(np.ceil(ntrain4/BATCH_SIZE))\n",
        "nevalbatches4 = int(np.ceil(neval4/BATCH_SIZE))\n",
        "print(\"number of train batches \", ntrainbatches4)\n",
        "print(\"number of eval batches \", nevalbatches4)\n",
        "\n",
        "#total number of batches in the train and eval dataset\n",
        "\n",
        "ntrain5 = train5.shape[0]\n",
        "neval5 = eval5.shape[0]\n",
        "print(ntrain5)\n",
        "print(neval5)\n",
        "\n",
        "#total number of samples in the train and eval dataset\n",
        "\n",
        "ntrainbatches5 = int(np.ceil(ntrain5/BATCH_SIZE))\n",
        "nevalbatches5 = int(np.ceil(neval5/BATCH_SIZE))\n",
        "print(\"number of train batches \", ntrainbatches5)\n",
        "print(\"number of eval batches \", nevalbatches5)\n",
        "\n",
        "#total number of batches in the train and eval dataset\n",
        "\n",
        "ntrain6 = train6.shape[0]\n",
        "neval6 = eval6.shape[0]\n",
        "print(ntrain6)\n",
        "print(neval6)\n",
        "\n",
        "#total number of samples in the train and eval dataset\n",
        "\n",
        "ntrainbatches6 = int(np.ceil(ntrain6/BATCH_SIZE))\n",
        "nevalbatches6 = int(np.ceil(neval6/BATCH_SIZE))\n",
        "print(\"number of train batches \", ntrainbatches6)\n",
        "print(\"number of eval batches \", nevalbatches6)\n",
        "\n",
        "#total number of batches in the train and eval dataset\n",
        "\n",
        "ntrain7 = train7.shape[0]\n",
        "neval7 = eval7.shape[0]\n",
        "print(ntrain7)\n",
        "print(neval7)\n",
        "\n",
        "#total number of samples in the train and eval dataset\n",
        "\n",
        "ntrainbatches7 = int(np.ceil(ntrain7/BATCH_SIZE))\n",
        "nevalbatches7 = int(np.ceil(neval7/BATCH_SIZE))\n",
        "print(\"number of train batches \", ntrainbatches7)\n",
        "print(\"number of eval batches \", nevalbatches7)\n",
        "\n",
        "#total number of batches in the train and eval dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OdhtswLKaCJZ"
      },
      "outputs": [],
      "source": [
        "# Functions for training and evaluation on the whole dataset for one epoch\n",
        "\n",
        "def train_epoch1(model, optimizer):\n",
        "    model.train()\n",
        "    losses = 0\n",
        "    train_iter = MyIterableDataset(train1[TGT_LANGUAGE], train1[SRC_LANGUAGE1])\n",
        "    train_dataloader = DataLoader(train_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn1)\n",
        "    for src, tgt in train_dataloader:\n",
        "\n",
        "        src = src.to(DEVICE)\n",
        "        tgt = tgt.to(DEVICE)\n",
        "\n",
        "        tgt_input = tgt[:-1, :]\n",
        "\n",
        "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
        "\n",
        "\n",
        "        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask,'Hindi')\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        tgt_out = tgt[1:, :]\n",
        "\n",
        "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "        losses += loss.item()\n",
        "\n",
        "    print(\"train losses \", losses)\n",
        "    return losses / ntrainbatches1\n",
        "\n",
        "def train_epoch2(model, optimizer):\n",
        "    model.train()\n",
        "    losses = 0\n",
        "    train_iter = MyIterableDataset(train2[TGT_LANGUAGE], train2[SRC_LANGUAGE2])\n",
        "    train_dataloader = DataLoader(train_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn2)\n",
        "    for src, tgt in train_dataloader:\n",
        "\n",
        "        src = src.to(DEVICE)\n",
        "        tgt = tgt.to(DEVICE)\n",
        "\n",
        "        tgt_input = tgt[:-1, :]\n",
        "\n",
        "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
        "\n",
        "\n",
        "        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask,'Gujarati')\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        tgt_out = tgt[1:, :]\n",
        "\n",
        "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "        losses += loss.item()\n",
        "\n",
        "    print(\"train losses \", losses)\n",
        "    return losses / ntrainbatches2\n",
        "\n",
        "def train_epoch3(model, optimizer):\n",
        "    model.train()\n",
        "    losses = 0\n",
        "    train_iter = MyIterableDataset(train3[TGT_LANGUAGE], train3[SRC_LANGUAGE3])\n",
        "    train_dataloader = DataLoader(train_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn3)\n",
        "    for src, tgt in train_dataloader:\n",
        "\n",
        "        src = src.to(DEVICE)\n",
        "        tgt = tgt.to(DEVICE)\n",
        "\n",
        "        tgt_input = tgt[:-1, :]\n",
        "\n",
        "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
        "\n",
        "\n",
        "        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask,'Gujarati')\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        tgt_out = tgt[1:, :]\n",
        "\n",
        "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "        losses += loss.item()\n",
        "\n",
        "    print(\"train losses \", losses)\n",
        "    return losses / ntrainbatches3\n",
        "\n",
        "def train_epoch4(model, optimizer):\n",
        "    model.train()\n",
        "    losses = 0\n",
        "    train_iter = MyIterableDataset(train4[TGT_LANGUAGE], train4[SRC_LANGUAGE4])\n",
        "    train_dataloader = DataLoader(train_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn4)\n",
        "    for src, tgt in train_dataloader:\n",
        "\n",
        "        src = src.to(DEVICE)\n",
        "        tgt = tgt.to(DEVICE)\n",
        "\n",
        "        tgt_input = tgt[:-1, :]\n",
        "\n",
        "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
        "\n",
        "\n",
        "        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask,'Gujarati')\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        tgt_out = tgt[1:, :]\n",
        "\n",
        "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "        losses += loss.item()\n",
        "\n",
        "    print(\"train losses \", losses)\n",
        "    return losses / ntrainbatches4\n",
        "\n",
        "def train_epoch5(model, optimizer):\n",
        "    model.train()\n",
        "    losses = 0\n",
        "    train_iter = MyIterableDataset(train5[TGT_LANGUAGE], train5[SRC_LANGUAGE5])\n",
        "    train_dataloader = DataLoader(train_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn5)\n",
        "    for src, tgt in train_dataloader:\n",
        "\n",
        "        src = src.to(DEVICE)\n",
        "        tgt = tgt.to(DEVICE)\n",
        "\n",
        "        tgt_input = tgt[:-1, :]\n",
        "\n",
        "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
        "\n",
        "\n",
        "        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask,'Gujarati')\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        tgt_out = tgt[1:, :]\n",
        "\n",
        "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "        losses += loss.item()\n",
        "\n",
        "    print(\"train losses \", losses)\n",
        "    return losses / ntrainbatches5\n",
        "\n",
        "def train_epoch6(model, optimizer):\n",
        "    model.train()\n",
        "    losses = 0\n",
        "    train_iter = MyIterableDataset(train6[TGT_LANGUAGE], train6[SRC_LANGUAGE6])\n",
        "    train_dataloader = DataLoader(train_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn6)\n",
        "    for src, tgt in train_dataloader:\n",
        "\n",
        "        src = src.to(DEVICE)\n",
        "        tgt = tgt.to(DEVICE)\n",
        "\n",
        "        tgt_input = tgt[:-1, :]\n",
        "\n",
        "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
        "\n",
        "\n",
        "        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask,'Gujarati')\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        tgt_out = tgt[1:, :]\n",
        "\n",
        "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "        losses += loss.item()\n",
        "\n",
        "    print(\"train losses \", losses)\n",
        "    return losses / ntrainbatches6\n",
        "\n",
        "def train_epoch7(model, optimizer):\n",
        "    model.train()\n",
        "    losses = 0\n",
        "    train_iter = MyIterableDataset(train7[TGT_LANGUAGE], train7[SRC_LANGUAGE7])\n",
        "    train_dataloader = DataLoader(train_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn7)\n",
        "    for src, tgt in train_dataloader:\n",
        "\n",
        "        src = src.to(DEVICE)\n",
        "        tgt = tgt.to(DEVICE)\n",
        "\n",
        "        tgt_input = tgt[:-1, :]\n",
        "\n",
        "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
        "\n",
        "\n",
        "        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask,'Gujarati')\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        tgt_out = tgt[1:, :]\n",
        "\n",
        "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "        losses += loss.item()\n",
        "\n",
        "    print(\"train losses \", losses)\n",
        "    return losses / ntrainbatches7\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def evaluate1(model):\n",
        "    model.eval()\n",
        "    losses = 0\n",
        "\n",
        "\n",
        "    eval_iter = MyIterableDataset(eval1[TGT_LANGUAGE], eval1[SRC_LANGUAGE1])\n",
        "    val_dataloader = DataLoader(eval_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn1)\n",
        "\n",
        "\n",
        "    for src, tgt in val_dataloader:\n",
        "        src = src.to(DEVICE)\n",
        "        tgt = tgt.to(DEVICE)\n",
        "\n",
        "        tgt_input = tgt[:-1, :]\n",
        "\n",
        "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
        "\n",
        "        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask,'Hindi')\n",
        "\n",
        "        tgt_out = tgt[1:, :]\n",
        "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
        "        losses += loss.item()\n",
        "    print(\"validation losses \", losses)\n",
        "    return losses / nevalbatches1\n",
        "\n",
        "def evaluate2(model):\n",
        "    model.eval()\n",
        "    losses = 0\n",
        "\n",
        "\n",
        "    eval_iter = MyIterableDataset(eval2[TGT_LANGUAGE], eval2[SRC_LANGUAGE2])\n",
        "    val_dataloader = DataLoader(eval_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn2)\n",
        "\n",
        "\n",
        "    for src, tgt in val_dataloader:\n",
        "        src = src.to(DEVICE)\n",
        "        tgt = tgt.to(DEVICE)\n",
        "\n",
        "        tgt_input = tgt[:-1, :]\n",
        "\n",
        "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
        "\n",
        "        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask,'Gujarati')\n",
        "\n",
        "        tgt_out = tgt[1:, :]\n",
        "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
        "        losses += loss.item()\n",
        "    print(\"validation losses \", losses)\n",
        "    return losses / nevalbatches2\n",
        "\n",
        "def evaluate3(model):\n",
        "    model.eval()\n",
        "    losses = 0\n",
        "\n",
        "\n",
        "    eval_iter = MyIterableDataset(eval3[TGT_LANGUAGE], eval3[SRC_LANGUAGE3])\n",
        "    val_dataloader = DataLoader(eval_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn3)\n",
        "\n",
        "\n",
        "    for src, tgt in val_dataloader:\n",
        "        src = src.to(DEVICE)\n",
        "        tgt = tgt.to(DEVICE)\n",
        "\n",
        "        tgt_input = tgt[:-1, :]\n",
        "\n",
        "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
        "\n",
        "        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask,'Gujarati')\n",
        "\n",
        "        tgt_out = tgt[1:, :]\n",
        "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
        "        losses += loss.item()\n",
        "    print(\"validation losses \", losses)\n",
        "    return losses / nevalbatches3\n",
        "\n",
        "def evaluate4(model):\n",
        "    model.eval()\n",
        "    losses = 0\n",
        "\n",
        "\n",
        "    eval_iter = MyIterableDataset(eval4[TGT_LANGUAGE], eval4[SRC_LANGUAGE4])\n",
        "    val_dataloader = DataLoader(eval_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn4)\n",
        "\n",
        "\n",
        "    for src, tgt in val_dataloader:\n",
        "        src = src.to(DEVICE)\n",
        "        tgt = tgt.to(DEVICE)\n",
        "\n",
        "        tgt_input = tgt[:-1, :]\n",
        "\n",
        "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
        "\n",
        "        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask,'Gujarati')\n",
        "\n",
        "        tgt_out = tgt[1:, :]\n",
        "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
        "        losses += loss.item()\n",
        "    print(\"validation losses \", losses)\n",
        "    return losses / nevalbatches4\n",
        "\n",
        "def evaluate5(model):\n",
        "    model.eval()\n",
        "    losses = 0\n",
        "\n",
        "\n",
        "    eval_iter = MyIterableDataset(eval5[TGT_LANGUAGE], eval5[SRC_LANGUAGE5])\n",
        "    val_dataloader = DataLoader(eval_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn5)\n",
        "\n",
        "\n",
        "    for src, tgt in val_dataloader:\n",
        "        src = src.to(DEVICE)\n",
        "        tgt = tgt.to(DEVICE)\n",
        "\n",
        "        tgt_input = tgt[:-1, :]\n",
        "\n",
        "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
        "\n",
        "        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask,'Gujarati')\n",
        "\n",
        "        tgt_out = tgt[1:, :]\n",
        "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
        "        losses += loss.item()\n",
        "    print(\"validation losses \", losses)\n",
        "    return losses / nevalbatches5\n",
        "\n",
        "def evaluate6(model):\n",
        "    model.eval()\n",
        "    losses = 0\n",
        "\n",
        "\n",
        "    eval_iter = MyIterableDataset(eval6[TGT_LANGUAGE], eval6[SRC_LANGUAGE6])\n",
        "    val_dataloader = DataLoader(eval_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn6)\n",
        "\n",
        "\n",
        "    for src, tgt in val_dataloader:\n",
        "        src = src.to(DEVICE)\n",
        "        tgt = tgt.to(DEVICE)\n",
        "\n",
        "        tgt_input = tgt[:-1, :]\n",
        "\n",
        "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
        "\n",
        "        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask,'Gujarati')\n",
        "\n",
        "        tgt_out = tgt[1:, :]\n",
        "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
        "        losses += loss.item()\n",
        "    print(\"validation losses \", losses)\n",
        "    return losses / nevalbatches6\n",
        "\n",
        "def evaluate7(model):\n",
        "    model.eval()\n",
        "    losses = 0\n",
        "\n",
        "\n",
        "    eval_iter = MyIterableDataset(eval7[TGT_LANGUAGE], eval7[SRC_LANGUAGE7])\n",
        "    val_dataloader = DataLoader(eval_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn7)\n",
        "\n",
        "\n",
        "    for src, tgt in val_dataloader:\n",
        "        src = src.to(DEVICE)\n",
        "        tgt = tgt.to(DEVICE)\n",
        "\n",
        "        tgt_input = tgt[:-1, :]\n",
        "\n",
        "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
        "\n",
        "        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask,'Gujarati')\n",
        "\n",
        "        tgt_out = tgt[1:, :]\n",
        "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
        "        losses += loss.item()\n",
        "    print(\"validation losses \", losses)\n",
        "    return losses / nevalbatches7"
      ],
      "metadata": {
        "id": "COSXlGJP0zrM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NGyQpL0KTirY"
      },
      "outputs": [],
      "source": [
        "!export CUDA_LAUNCH_BLOCKING=1 #might give error some time, just comment out if it does so"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b2o2Vav-4_mw"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rTSyNGN47lW",
        "outputId": "3c81f3df-e313-4a17-ed1d-7507dd80ce93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Oct 26 19:55:58 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P0    25W /  70W |   1537MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VX3UFpM4aCJd"
      },
      "outputs": [],
      "source": [
        "#training loop\n",
        "# prev_val_loss = 0\n",
        "# for epoch in range(1, 2*NUM_EPOCHS+1):\n",
        "#     start_time = timer()\n",
        "\n",
        "#     train_loss1 = train_epoch1(transformer, optimizer)\n",
        "\n",
        "#     end_time = timer()\n",
        "#     val_loss1 = evaluate1(transformer)\n",
        "\n",
        "\n",
        "#     print((f\"Epoch: {epoch}, Train loss: {train_loss1:.3f}, Val loss: {val_loss1:.3f}, \"f\"Epoch time = {(end_time - start_time):.3f}s\"))\n",
        "\n",
        "#     start_time = timer()\n",
        "\n",
        "#     train_loss2 = train_epoch2(transformer, optimizer)\n",
        "\n",
        "#     end_time = timer()\n",
        "#     val_loss2 = evaluate2(transformer)\n",
        "\n",
        "#     print((f\"Epoch: {epoch}, Train loss: {train_loss2:.3f}, Val loss: {val_loss2:.3f}, \"f\"Epoch time = {(end_time - start_time):.3f}s\"))\n",
        "\n",
        "#     start_time = timer()\n",
        "\n",
        "#     train_loss3 = train_epoch3(transformer, optimizer)\n",
        "\n",
        "#     end_time = timer()\n",
        "#     val_loss3 = evaluate3(transformer)\n",
        "\n",
        "#     print((f\"Epoch: {epoch}, Train loss: {train_loss3:.3f}, Val loss: {val_loss3:.3f}, \"f\"Epoch time = {(end_time - start_time):.3f}s\"))\n",
        "\n",
        "#     start_time = timer()\n",
        "\n",
        "#     train_loss4 = train_epoch4(transformer, optimizer)\n",
        "\n",
        "#     end_time = timer()\n",
        "#     val_loss4 = evaluate4(transformer)\n",
        "\n",
        "#     print((f\"Epoch: {epoch}, Train loss: {train_loss4:.3f}, Val loss: {val_loss4:.3f}, \"f\"Epoch time = {(end_time - start_time):.3f}s\"))\n",
        "\n",
        "#     start_time = timer()\n",
        "\n",
        "#     train_loss5 = train_epoch5(transformer, optimizer)\n",
        "\n",
        "#     end_time = timer()\n",
        "#     val_loss5 = evaluate5(transformer)\n",
        "\n",
        "#     print((f\"Epoch: {epoch}, Train loss: {train_loss5:.3f}, Val loss: {val_loss5:.3f}, \"f\"Epoch time = {(end_time - start_time):.3f}s\"))\n",
        "\n",
        "#     start_time = timer()\n",
        "\n",
        "#     train_loss6 = train_epoch6(transformer, optimizer)\n",
        "\n",
        "#     end_time = timer()\n",
        "#     val_loss6 = evaluate6(transformer)\n",
        "\n",
        "#     print((f\"Epoch: {epoch}, Train loss: {train_loss6:.3f}, Val loss: {val_loss6:.3f}, \"f\"Epoch time = {(end_time - start_time):.3f}s\"))\n",
        "\n",
        "#     start_time = timer()\n",
        "\n",
        "#     train_loss7 = train_epoch7(transformer, optimizer)\n",
        "\n",
        "#     end_time = timer()\n",
        "#     val_loss7 = evaluate7(transformer)\n",
        "\n",
        "#     print((f\"Epoch: {epoch}, Train loss: {train_loss7:.3f}, Val loss: {val_loss7:.3f}, \"f\"Epoch time = {(end_time - start_time):.3f}s\"))\n",
        "\n",
        "#     if epoch == 1:\n",
        "#         prev_val_loss1 = val_loss1\n",
        "#         prev_val_loss2 = val_loss2\n",
        "#         prev_val_loss3 = val_loss3\n",
        "#         prev_val_loss4 = val_loss4\n",
        "#         prev_val_loss5 = val_loss5\n",
        "#         prev_val_loss6 = val_loss6\n",
        "#         prev_val_loss7 = val_loss7\n",
        "\n",
        "#     else:\n",
        "#         e1 = prev_val_loss1 - val_loss1\n",
        "#         e2 = prev_val_loss2 - val_loss2\n",
        "#         e3 = prev_val_loss3 - val_loss3\n",
        "#         e4 = prev_val_loss4 - val_loss4\n",
        "#         e5 = prev_val_loss5 - val_loss5\n",
        "#         e6 = prev_val_loss6 - val_loss6\n",
        "#         e7 = prev_val_loss7 - val_loss7\n",
        "#         if e1 < 0.001 and e2 < 0.001 and e7 < 0.001 and e3 < 0.001 and e4 < 0.001 and e5 < 0.001 and e6 < 0.001:\n",
        "#             break\n",
        "#         prev_val_loss1 = val_loss1\n",
        "#         prev_val_loss2 = val_loss2\n",
        "#         prev_val_loss3 = val_loss3\n",
        "#         prev_val_loss4 = val_loss4\n",
        "#         prev_val_loss5 = val_loss5\n",
        "#         prev_val_loss6 = val_loss6\n",
        "#         prev_val_loss7 = val_loss7\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transformer.load_state_dict(torch.load('/content/drive/My Drive/My Folder/MultiEncAll_loss2_iter2_4.pt'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "id": "1jkOFdYfut5p",
        "outputId": "e8298638-04e4-47d2-cbe7-f3cbdafa5408"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-62-4e36076cfa0e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/My Folder/MultiEncAll_loss2_iter2_4.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1012\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpicklingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mUNSAFE_MESSAGE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m                 return _load(opened_zipfile,\n\u001b[0m\u001b[1;32m   1015\u001b[0m                              \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m                              \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnpicklerWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1421\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1422\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_loaded_sparse_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mpersistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1390\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m             \u001b[0mnbytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumel\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_element_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1392\u001b[0;31m             \u001b[0mtyped_storage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_maybe_decode_ascii\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtyped_storage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m   1364\u001b[0m         \u001b[0;31m# stop wrapping with TypedStorage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1365\u001b[0m         typed_storage = torch.storage.TypedStorage(\n\u001b[0;32m-> 1366\u001b[0;31m             \u001b[0mwrap_storage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrestore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1367\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1368\u001b[0m             _internal=True)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdefault_restore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_package_registry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_cuda_deserialize\u001b[0;34m(obj, location)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_cuda_deserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m         \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_cuda_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_torch_load_uninitialized\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mvalidate_cuda_device\u001b[0;34m(location)\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0mdevice_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mdevice_count\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m         raise RuntimeError('Attempting to deserialize object on CUDA device '\n\u001b[0m\u001b[1;32m    266\u001b[0m                            \u001b[0;34mf'{device} but torch.cuda.device_count() is {device_count}. Please use '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m                            \u001b[0;34m'torch.load with map_location to map your storages '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Attempting to deserialize object on CUDA device 1 but torch.cuda.device_count() is 1. Please use torch.load with map_location to map your storages to an existing device."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SutpsX_3TirY"
      },
      "outputs": [],
      "source": [
        "'''functions for decoding the final output tensor into the english sentence. We have used\n",
        "two types of decoding techniques namely beam search decode and greedy decode. Although\n",
        "we have used only the greedy decode scheme for our purpose for the reason that it takes\n",
        "less '''\n",
        "\n",
        "import heapq\n",
        "import nltk\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "\n",
        "\n",
        "def greedy_decode1(model, src, src_mask, max_len, start_symbol):\n",
        "    src = src.to(DEVICE)\n",
        "    src_mask = src_mask.to(DEVICE)\n",
        "\n",
        "    memory = model.encode(src, src_mask,SRC_LANGUAGE1)\n",
        "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n",
        "    for i in range(max_len-1):\n",
        "        memory = memory.to(DEVICE)\n",
        "        tgt_mask = (generate_square_subsequent_mask(ys.size(0))\n",
        "                    .type(torch.bool)).to(DEVICE)\n",
        "        out = model.decode(ys, memory, tgt_mask)\n",
        "        out = out.transpose(0, 1)\n",
        "        prob = model.generator(out[:, -1])\n",
        "        _, next_word = torch.max(prob, dim=1)\n",
        "        next_word = next_word.item()\n",
        "\n",
        "        ys = torch.cat([ys,\n",
        "                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n",
        "        if next_word == EOS_IDX:\n",
        "            break\n",
        "    return ys\n",
        "\n",
        "# actual function to translate input sentence into target language\n",
        "def translate1(model: torch.nn.Module, src_sentence: str):\n",
        "    model.eval()\n",
        "    src = text_transform1[SRC_LANGUAGE1](src_sentence).view(-1, 1)\n",
        "    num_tokens = src.shape[0]\n",
        "    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
        "    tgt_tokens = greedy_decode1(\n",
        "        model,  src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX).flatten()\n",
        "    return \" \".join(vocab_transform1[TGT_LANGUAGE].lookup_tokens(list(tgt_tokens.cpu().numpy()))).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\")\n",
        "\n",
        "\n",
        "def greedy_decode2(model, src, src_mask, max_len, start_symbol):\n",
        "    src = src.to(DEVICE)\n",
        "    src_mask = src_mask.to(DEVICE)\n",
        "\n",
        "    memory = model.encode(src, src_mask,SRC_LANGUAGE2)\n",
        "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n",
        "    for i in range(max_len-1):\n",
        "        memory = memory.to(DEVICE)\n",
        "        tgt_mask = (generate_square_subsequent_mask(ys.size(0))\n",
        "                    .type(torch.bool)).to(DEVICE)\n",
        "        out = model.decode(ys, memory, tgt_mask)\n",
        "        out = out.transpose(0, 1)\n",
        "        prob = model.generator(out[:, -1])\n",
        "        _, next_word = torch.max(prob, dim=1)\n",
        "        next_word = next_word.item()\n",
        "\n",
        "        ys = torch.cat([ys,\n",
        "                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n",
        "        if next_word == EOS_IDX:\n",
        "            break\n",
        "    return ys\n",
        "\n",
        "\n",
        "# actual function to translate input sentence into target language\n",
        "def translate2(model: torch.nn.Module, src_sentence: str):\n",
        "    model.eval()\n",
        "    src = text_transform2[SRC_LANGUAGE2](src_sentence).view(-1, 1)\n",
        "    num_tokens = src.shape[0]\n",
        "    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
        "    tgt_tokens = greedy_decode2(\n",
        "        model,  src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX).flatten()\n",
        "    return \" \".join(vocab_transform2[TGT_LANGUAGE].lookup_tokens(list(tgt_tokens.cpu().numpy()))).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\")\n",
        "\n",
        "\n",
        "\n",
        "def greedy_decode3(model, src, src_mask, max_len, start_symbol):\n",
        "    src = src.to(DEVICE)\n",
        "    src_mask = src_mask.to(DEVICE)\n",
        "\n",
        "    memory = model.encode(src, src_mask,SRC_LANGUAGE3)\n",
        "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n",
        "    for i in range(max_len-1):\n",
        "        memory = memory.to(DEVICE)\n",
        "        tgt_mask = (generate_square_subsequent_mask(ys.size(0))\n",
        "                    .type(torch.bool)).to(DEVICE)\n",
        "        out = model.decode(ys, memory, tgt_mask)\n",
        "        out = out.transpose(0, 1)\n",
        "        prob = model.generator(out[:, -1])\n",
        "        _, next_word = torch.max(prob, dim=1)\n",
        "        next_word = next_word.item()\n",
        "\n",
        "        ys = torch.cat([ys,\n",
        "                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n",
        "        if next_word == EOS_IDX:\n",
        "            break\n",
        "    return ys\n",
        "\n",
        "\n",
        "\n",
        "# actual function to translate input sentence into target language\n",
        "def translate3(model: torch.nn.Module, src_sentence: str):\n",
        "    model.eval()\n",
        "    src = text_transform3[SRC_LANGUAGE3](src_sentence).view(-1, 1)\n",
        "    num_tokens = src.shape[0]\n",
        "    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
        "    tgt_tokens = greedy_decode3(\n",
        "        model,  src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX).flatten()\n",
        "    return \" \".join(vocab_transform3[TGT_LANGUAGE].lookup_tokens(list(tgt_tokens.cpu().numpy()))).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\")\n",
        "\n",
        "def greedy_decode4(model, src, src_mask, max_len, start_symbol):\n",
        "    src = src.to(DEVICE)\n",
        "    src_mask = src_mask.to(DEVICE)\n",
        "\n",
        "    memory = model.encode(src, src_mask,SRC_LANGUAGE4)\n",
        "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n",
        "    for i in range(max_len-1):\n",
        "        memory = memory.to(DEVICE)\n",
        "        tgt_mask = (generate_square_subsequent_mask(ys.size(0))\n",
        "                    .type(torch.bool)).to(DEVICE)\n",
        "        out = model.decode(ys, memory, tgt_mask)\n",
        "        out = out.transpose(0, 1)\n",
        "        prob = model.generator(out[:, -1])\n",
        "        _, next_word = torch.max(prob, dim=1)\n",
        "        next_word = next_word.item()\n",
        "\n",
        "        ys = torch.cat([ys,\n",
        "                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n",
        "        if next_word == EOS_IDX:\n",
        "            break\n",
        "    return ys\n",
        "\n",
        "\n",
        "\n",
        "# actual function to translate input sentence into target language\n",
        "def translate4(model: torch.nn.Module, src_sentence: str):\n",
        "    model.eval()\n",
        "    src = text_transform4[SRC_LANGUAGE4](src_sentence).view(-1, 1)\n",
        "    num_tokens = src.shape[0]\n",
        "    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
        "    tgt_tokens = greedy_decode4(\n",
        "        model,  src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX).flatten()\n",
        "    return \" \".join(vocab_transform4[TGT_LANGUAGE].lookup_tokens(list(tgt_tokens.cpu().numpy()))).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\")\n",
        "\n",
        "\n",
        "def greedy_decode5(model, src, src_mask, max_len, start_symbol):\n",
        "    src = src.to(DEVICE)\n",
        "    src_mask = src_mask.to(DEVICE)\n",
        "\n",
        "    memory = model.encode(src, src_mask,SRC_LANGUAGE5)\n",
        "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n",
        "    for i in range(max_len-1):\n",
        "        memory = memory.to(DEVICE)\n",
        "        tgt_mask = (generate_square_subsequent_mask(ys.size(0))\n",
        "                    .type(torch.bool)).to(DEVICE)\n",
        "        out = model.decode(ys, memory, tgt_mask)\n",
        "        out = out.transpose(0, 1)\n",
        "        prob = model.generator(out[:, -1])\n",
        "        _, next_word = torch.max(prob, dim=1)\n",
        "        next_word = next_word.item()\n",
        "\n",
        "        ys = torch.cat([ys,\n",
        "                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n",
        "        if next_word == EOS_IDX:\n",
        "            break\n",
        "    return ys\n",
        "\n",
        "\n",
        "\n",
        "# actual function to translate input sentence into target language\n",
        "def translate5(model: torch.nn.Module, src_sentence: str):\n",
        "    model.eval()\n",
        "    src = text_transform5[SRC_LANGUAGE5](src_sentence).view(-1, 1)\n",
        "    num_tokens = src.shape[0]\n",
        "    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
        "    tgt_tokens = greedy_decode5(\n",
        "        model,  src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX).flatten()\n",
        "    return \" \".join(vocab_transform5[TGT_LANGUAGE].lookup_tokens(list(tgt_tokens.cpu().numpy()))).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\")\n",
        "\n",
        "\n",
        "def greedy_decode6(model, src, src_mask, max_len, start_symbol):\n",
        "    src = src.to(DEVICE)\n",
        "    src_mask = src_mask.to(DEVICE)\n",
        "\n",
        "    memory = model.encode(src, src_mask,SRC_LANGUAGE6)\n",
        "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n",
        "    for i in range(max_len-1):\n",
        "        memory = memory.to(DEVICE)\n",
        "        tgt_mask = (generate_square_subsequent_mask(ys.size(0))\n",
        "                    .type(torch.bool)).to(DEVICE)\n",
        "        out = model.decode(ys, memory, tgt_mask)\n",
        "        out = out.transpose(0, 1)\n",
        "        prob = model.generator(out[:, -1])\n",
        "        _, next_word = torch.max(prob, dim=1)\n",
        "        next_word = next_word.item()\n",
        "\n",
        "        ys = torch.cat([ys,\n",
        "                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n",
        "        if next_word == EOS_IDX:\n",
        "            break\n",
        "    return ys\n",
        "\n",
        "\n",
        "\n",
        "# actual function to translate input sentence into target language\n",
        "def translate6(model: torch.nn.Module, src_sentence: str):\n",
        "    model.eval()\n",
        "    src = text_transform6[SRC_LANGUAGE6](src_sentence).view(-1, 1)\n",
        "    num_tokens = src.shape[0]\n",
        "    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
        "    tgt_tokens = greedy_decode6(\n",
        "        model,  src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX).flatten()\n",
        "    return \" \".join(vocab_transform6[TGT_LANGUAGE].lookup_tokens(list(tgt_tokens.cpu().numpy()))).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def greedy_decode7(model, src, src_mask, max_len, start_symbol):\n",
        "    src = src.to(DEVICE)\n",
        "    src_mask = src_mask.to(DEVICE)\n",
        "\n",
        "    memory = model.encode(src, src_mask,SRC_LANGUAGE7)\n",
        "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n",
        "    for i in range(max_len-1):\n",
        "        memory = memory.to(DEVICE)\n",
        "        tgt_mask = (generate_square_subsequent_mask(ys.size(0))\n",
        "                    .type(torch.bool)).to(DEVICE)\n",
        "        out = model.decode(ys, memory, tgt_mask)\n",
        "        out = out.transpose(0, 1)\n",
        "        prob = model.generator(out[:, -1])\n",
        "        _, next_word = torch.max(prob, dim=1)\n",
        "        next_word = next_word.item()\n",
        "\n",
        "        ys = torch.cat([ys,\n",
        "                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n",
        "        if next_word == EOS_IDX:\n",
        "            break\n",
        "    return ys\n",
        "\n",
        "\n",
        "\n",
        "# actual function to translate input sentence into target language\n",
        "def translate7(model: torch.nn.Module, src_sentence: str):\n",
        "    model.eval()\n",
        "    src = text_transform7[SRC_LANGUAGE7](src_sentence).view(-1, 1)\n",
        "    num_tokens = src.shape[0]\n",
        "    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
        "    tgt_tokens = greedy_decode7(\n",
        "        model,  src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX).flatten()\n",
        "    return \" \".join(vocab_transform7[TGT_LANGUAGE].lookup_tokens(list(tgt_tokens.cpu().numpy()))).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "75jCKMD8TirZ"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "with open('/content/drive/My Drive/My Folder/MultiEncAll.txt', 'w', encoding = 'utf-8') as f:\n",
        "  # for sentence in final_test_data1['sentence']:\n",
        "  #   translated = translate1(transformer, sentence)\n",
        "  #   # print(type(translated))\n",
        "\n",
        "  #   f.write(translated + '\\n')\n",
        "\n",
        "  # for sentence in final_test_data2['sentence']:\n",
        "  #   translated = translate2(transformer, sentence)\n",
        "  #   # print(type(translated))\n",
        "\n",
        "  #   f.write(translated + '\\n')\n",
        "\n",
        "  # for sentence in final_test_data3['sentence']:\n",
        "  #   translated = translate3(transformer, sentence)\n",
        "  #   # print(type(translated))\n",
        "\n",
        "  #   f.write(translated + '\\n')\n",
        "\n",
        "  for sentence in tqdm(final_test_data4['sentence']):\n",
        "    translated = translate4(transformer, sentence)\n",
        "    # print(type(translated))\n",
        "\n",
        "    f.write(translated + '\\n')\n",
        "\n",
        "  for sentence in tqdm(final_test_data5['sentence']):\n",
        "    translated = translate5(transformer, sentence)\n",
        "    # print(type(translated))\n",
        "\n",
        "    f.write(translated + '\\n')\n",
        "\n",
        "  # for sentence in final_test_data6['sentence']:\n",
        "  #   translated = translate6(transformer, sentence)\n",
        "  #   # print(type(translated))\n",
        "\n",
        "  #   f.write(translated + '\\n')\n",
        "\n",
        "  # for sentence in final_test_data7['sentence']:\n",
        "  #   translated = translate7(transformer, sentence)\n",
        "  #   # print(type(translated))\n",
        "\n",
        "  #   f.write(translated + '\\n')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}